{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Prep"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T10:30:03.334868Z","iopub.status.busy":"2024-07-10T10:30:03.334549Z","iopub.status.idle":"2024-07-10T10:30:13.163038Z","shell.execute_reply":"2024-07-10T10:30:13.161739Z","shell.execute_reply.started":"2024-07-10T10:30:03.334833Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-01 17:04:27.861376: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-09-01 17:04:27.872033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-01 17:04:27.883110: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-01 17:04:27.886488: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-01 17:04:27.893883: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-01 17:04:28.499309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-09-01 17:04:34,591\tINFO worker.py:1788 -- Started a local Ray instance.\n"]},{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  0\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1725203076.423939   11263 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-09-01 17:04:36.424852: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import os\n","import itertools\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, matthews_corrcoef\n","from sklearn.preprocessing import LabelBinarizer\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, ReLU, Input\n","from tensorflow.keras.optimizers import Adam\n","from math import floor\n","\n","import psutil\n","import time\n","import logging\n","\n","# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","logger = logging.getLogger(__name__)\n","\n","import ray\n","from ray import tune\n","from ray.tune.schedulers import ASHAScheduler\n","from ray.air import session\n","from ray.tune.integration.keras import TuneReportCallback\n","from ray.tune.search.optuna import OptunaSearch\n","\n","import helper\n","\n","# Initialize Ray\n","ray.init(ignore_reinit_error=True)\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","#tf.debugging.set_log_device_placement(True)"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The file results/mtl_fnn/output_A2.pkl does not exist.\n","The file results/mtl_fnn/output_A3.pkl does not exist.\n","The file results/mtl_fnn/output_A4.pkl does not exist.\n","The file results/mtl_fnn/output_A12.pkl does not exist.\n","The file results/mtl_fnn/output_A21.pkl does not exist.\n"]}],"source":["files_to_delete = [\"results/mtl_fnn/output_A2.pkl\", \"results/mtl_fnn/output_A3.pkl\", \"results/mtl_fnn/output_A4.pkl\", \"results/mtl_fnn/output_A12.pkl\", \"results/mtl_fnn/output_A21.pkl\"]\n","\n","for file in files_to_delete:\n","    if os.path.exists(file):\n","        os.remove(file)\n","    else:\n","        print(f\"The file {file} does not exist.\")"]},{"cell_type":"markdown","metadata":{},"source":["## Feature-Based MTL model"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T10:30:16.513190Z","iopub.status.busy":"2024-07-10T10:30:16.512565Z","iopub.status.idle":"2024-07-10T10:30:16.519877Z","shell.execute_reply":"2024-07-10T10:30:16.518848Z","shell.execute_reply.started":"2024-07-10T10:30:16.513154Z"},"trusted":true},"outputs":[],"source":["import torch\n","\n","# Neural Network Definition\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","# TODO activation for now only relu\n","class FeatureBasedMTLModel(nn.Module):\n","    def __init__(self, hidden_layers_shared=[50,30], hidden_layers_outputs=[[10],[10],[10],[10],[10]], activation='relu', dropout=0.5):\n","        super(FeatureBasedMTLModel, self).__init__()\n","\n","        self.activation = activation\n","        self.dropout = dropout\n","\n","        # shared layers\n","        self.shared_layers = nn.ModuleList()\n","        input_dim = 30\n","        for hidden_layer in hidden_layers_shared:\n","            self.shared_layers.append(nn.Linear(input_dim, hidden_layer))\n","            self.shared_layers.append(nn.Dropout(self.dropout))  # Add dropout layer\n","            input_dim = hidden_layer\n","\n","        # output layers\n","        self.output_a2 = self.create_output_layers(hidden_layers_outputs[0], input_dim, 2)\n","        self.output_a3 = self.create_output_layers(hidden_layers_outputs[1], input_dim, 2)\n","        self.output_a4 = self.create_output_layers(hidden_layers_outputs[2], input_dim, 3)\n","        self.output_a12 = self.create_output_layers(hidden_layers_outputs[3], input_dim, 6)\n","        self.output_a21 = self.create_output_layers(hidden_layers_outputs[4], input_dim, 2)\n","\n","\n","    def create_output_layers(self, hidden_layers, input_dim, output_dim):\n","        layers = nn.ModuleList()\n","        for hidden_layer in hidden_layers:\n","            layers.append(nn.Linear(input_dim, hidden_layer))\n","            layers.append(nn.Dropout(self.dropout)) \n","            input_dim = hidden_layer\n","        layers.append(nn.Linear(input_dim, output_dim))\n","        return layers\n","\n","    def forward(self, x: torch.Tensor, task_id: str):\n","        # shared layers\n","        for layer in self.shared_layers:\n","            if self.activation == 'relu':\n","                x = F.relu(layer(x))\n","            elif self.activation == 'tanh':\n","                x = F.tanh(layer(x))\n","            elif self.activation == 'sigmoid':\n","                x = F.sigmoid(layer(x))\n","            else:\n","                raise ValueError(f'Invalid activation: {self.activation}')\n","\n","        \n","        # output layers\n","        if task_id == 'a2':\n","            return self.forward_output_layers(x, self.output_a2)\n","        elif task_id == 'a3':\n","            return self.forward_output_layers(x, self.output_a3)\n","        elif task_id == 'a4':\n","            return self.forward_output_layers(x, self.output_a4)\n","        elif task_id == 'a12':\n","            return self.forward_output_layers(x, self.output_a12)\n","        elif task_id == 'a21':\n","            return self.forward_output_layers(x, self.output_a21)\n","        else:\n","            raise ValueError(f'Invalid task_id: {task_id}')\n","        \n","\n","    def forward_output_layers(self, x, layers):\n","        for layer in layers[:-1]:\n","            if self.activation == 'relu':\n","                x = F.relu(layer(x))\n","            elif self.activation == 'tanh':\n","                x = F.tanh(layer(x))\n","            elif self.activation == 'sigmoid':\n","                x = F.sigmoid(layer(x))\n","            else:\n","                raise ValueError(f'Invalid activation: {self.activation}')\n","            \n","        x = layers[-1](x)\n","        return F.softmax(x, dim=1)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T10:30:17.291825Z","iopub.status.busy":"2024-07-10T10:30:17.290934Z","iopub.status.idle":"2024-07-10T10:30:17.298631Z","shell.execute_reply":"2024-07-10T10:30:17.297583Z","shell.execute_reply.started":"2024-07-10T10:30:17.291782Z"},"trusted":true},"outputs":[],"source":["\n","def create_batches(X_train, y_train, batch_size):\n","    X_train_batches = {'a2': {}, 'a3': {}, 'a4': {}, 'a12': {}, 'a21': {}}\n","    y_train_batches = {'a2': {}, 'a3': {}, 'a4': {}, 'a12': {}, 'a21': {}}\n","\n","    for dataset in helper.dataset_list:\n","\n","        for i in range(0, floor(len(X_train[dataset])/batch_size)):\n","                X_train_batches[dataset][str(i)] =  X_train[dataset].iloc[i* batch_size:i*batch_size+batch_size]\n","                y_train_batches[dataset][str(i)] =  y_train[dataset].iloc[i* batch_size:i* batch_size+batch_size]\n","\n","    return X_train_batches, y_train_batches\n","\n","# batchsize in this case refers to the size of batch per dataset\n","def train(model, X_train, y_train, num_epochs, batch_size, learning_rate):\n","        \n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = torch.optim.Adam(model.parameters())\n","\n","        max_number_of_batches = max(len(X_train[dataset]) // batch_size for dataset in helper.dataset_list)\n","\n","        X_train, y_train = create_batches(X_train, y_train, batch_size)\n","\n","        for epoch in range(num_epochs):\n","                optimizer.zero_grad()\n","\n","                losses_per_epoch = {'a2': 0, 'a3': 0, 'a4': 0, 'a12': 0, 'a21': 0}\n","\n","                for batch_number in range(0, max_number_of_batches):\n","\n","                        for dataset in helper.dataset_list:\n","\n","                                if len(X_train[dataset]) > batch_number:\n","\n","                                        X_train_tensor = torch.tensor(X_train[dataset][str(batch_number)].values, dtype=torch.float32)\n","                                        y_train_tensor= torch.tensor(y_train[dataset][str(batch_number)].values, dtype=torch.float32)\n","                                        outputs = model(X_train_tensor, task_id = dataset)\n","                                        loss = criterion(outputs, y_train_tensor)\n","\n","                                        losses_per_epoch[dataset] += loss\n","\n","                for dataset in helper.dataset_list:\n","                        losses_per_epoch[dataset] /= len(X_train[dataset])\n","\n","                # for now sum of average loss per dataset\n","                loss = sum(losses_per_epoch.values())\n","                loss.backward()\n","                optimizer.step()\n","\n","        return model\n","\n","\n","def mcc(fn, fp, tn, tp):\n","    return (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n","\n","def evaluate(model, X_test, y_test):\n","\n","    eval_dict = {'a2': {}, 'a3': {}, 'a4': {}, 'a12': {}, 'a21': {}}\n","    num_classes = {'a2': 2, 'a3': 2, 'a4': 3, 'a12': 6, 'a21': 2}\n","    for dataset in helper.dataset_list:\n","        X_test_tensor = torch.tensor(X_test[dataset].values, dtype=torch.float32)\n","        #y_test_tensor = torch.tensor(y_test[dataset].values, dtype=torch.float32)\n","        y_pred_tensor = model(X_test_tensor, task_id = dataset)\n","        y_pred = y_pred_tensor.detach().numpy()\n","        y_pred = np.argmax(y_pred, axis=1)\n","\n","        y_test_np = y_test[dataset].to_numpy()\n","        y_test_np = np.argmax(y_test_np, axis=1)\n","\n","        # Calculate classification metrics using one-hot encoded targets\n","        eval_dict[dataset]['accuracy'] = accuracy_score(y_test_np, y_pred)\n","        eval_dict[dataset]['micro_f1'] = f1_score(y_test_np, y_pred, average='micro')\n","        eval_dict[dataset]['macro_f1'] = f1_score(y_test_np, y_pred, average='macro')\n","        # gets 0 quite often...???\n","        eval_dict[dataset]['mcc'] = matthews_corrcoef(y_test_np, y_pred)\n","\n","    return eval_dict"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T10:30:17.753453Z","iopub.status.busy":"2024-07-10T10:30:17.753116Z","iopub.status.idle":"2024-07-10T10:30:17.765149Z","shell.execute_reply":"2024-07-10T10:30:17.764141Z","shell.execute_reply.started":"2024-07-10T10:30:17.753425Z"},"trusted":true},"outputs":[],"source":["def evaluate_model_on_dataset_one_split(split_index, config):\n","    \n","\n","    X_train, X_test, y_train, y_test =  helper.get_joined_train_test_folds(split_index)\n","\n","    model = FeatureBasedMTLModel(activation=config['activation'], hidden_layers_shared=config['shared_hidden_layers'], hidden_layers_outputs=[\n","        config['a2_output_hidden_layers'], config['a3_output_hidden_layers'], config['a4_output_hidden_layers'], config['a12_output_hidden_layers'], config['a21_output_hidden_layers']\n","    ], dropout=config['dropout_rate'])\n","\n","    # Train the model and collect performance data\n","    model = train(model, X_train, y_train, num_epochs=config['epochs'], batch_size=config['batch_size'], learning_rate=config['learning_rate'],)\n","    # Evaluate the model and collect performance data\n","    eval_dict = evaluate(model, X_test, y_test)\n","\n","    return eval_dict\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#evaluate_model_on_dataset_one_split(1, {\n","#    'activation': 'sigmoid',\n","#    'shared_hidden_layers': [50, 30],\n","#    'a2_output_hidden_layers': [10],\n","#    'a3_output_hidden_layers': [10],\n","#    'a4_output_hidden_layers': [10],\n","#    'a12_output_hidden_layers': [10],\n","#    'a21_output_hidden_layers': [10],\n","#    'epochs': 10,\n","#    'batch_size': 32,\n","#    'learning_rate': 0.001\n","#})"]},{"cell_type":"markdown","metadata":{},"source":["## 5-Fold-Cross Validation"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["df_data_spike_1_split = {\n","    'a2': pd.DataFrame(),\n","    'a3': pd.DataFrame(),\n","    'a4': pd.DataFrame(),\n","    'a12': pd.DataFrame(),\n","    'a21': pd.DataFrame()\n","}\n","\n","df_data_spike_full_split = pd.DataFrame()\n","\n","data_spike_exec_1_split_dict = dict()\n","data_spike_exec_full_split_dict = {\n","    'a2': {},\n","    'a3': {},\n","    'a4': {},\n","    'a12': {},\n","    'a21': {}\n","}\n","\n","\n","best_params_list_getting = []\n","\n","def custom_trial_dirname(trial):\n","    return f\"trial_{trial.trial_id}\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T10:30:21.118433Z","iopub.status.busy":"2024-07-10T10:30:21.118035Z","iopub.status.idle":"2024-07-10T11:21:07.299373Z","shell.execute_reply":"2024-07-10T11:21:07.298387Z","shell.execute_reply.started":"2024-07-10T10:30:21.118400Z"},"trusted":true},"outputs":[],"source":["def train_and_evaluate(config):\n","    \n","    global data_spike_exec_1_split_dict\n","    global data_spike_exec_full_split_dict\n","    global df_data_spike_1_split\n","    global results_dir\n","\n","    overall_result = {\n","    \"a2\": {\n","        \"accuracy_scores\": [],\n","        \"f1_macro_scores\": [],\n","        \"f1_micro_scores\": [],\n","        \"mcc_scores\": []\n","    },\n","    \"a3\": {\n","        \"accuracy_scores\": [],\n","        \"f1_macro_scores\": [],\n","        \"f1_micro_scores\": [],\n","        \"mcc_scores\": []\n","    },\n","    \"a4\": { \n","        \"accuracy_scores\": [],\n","        \"f1_macro_scores\": [],\n","        \"f1_micro_scores\": [],\n","        \"mcc_scores\": []\n","    },\n","    \"a12\": {\n","        \"accuracy_scores\": [],\n","        \"f1_macro_scores\": [],\n","        \"f1_micro_scores\": [],\n","        \"mcc_scores\": []\n","    },\n","    \"a21\": {\n","        \"accuracy_scores\": [],\n","        \"f1_macro_scores\": [],\n","        \"f1_micro_scores\": [],\n","        \"mcc_scores\": []\n","    }\n","    }\n","\n","    accuracy_scores = []\n","    f1_macro_scores = []\n","    f1_micro_scores = []\n","    mcc_scores = []\n","\n","    data_spike_exec_1_split_dict = {}\n","    for dataset in overall_result.keys():\n","        data_spike_exec_1_split_dict[dataset] = pd.DataFrame()\n","\n","    #session_id_for_df = session.get_trial_id()\n","    #print(type(session_id_for_df))\n","    \n","    # save individual results for each dataset\n","    for i in range(5):\n","        eval_dict = evaluate_model_on_dataset_one_split(i, config)\n","        # fill all nan values in eval_dict with 0\n","        for dataset in eval_dict.keys():\n","            for key in eval_dict[dataset].keys():\n","                if np.isnan(eval_dict[dataset][key]):\n","                    eval_dict[dataset][key] = 0\n","        \n","        for dataset in overall_result.keys():\n","\n","            overall_result[dataset]['accuracy_scores'].append(eval_dict[dataset]['accuracy'])\n","            overall_result[dataset]['f1_macro_scores'].append(eval_dict[dataset]['macro_f1'])\n","            overall_result[dataset]['f1_micro_scores'].append(eval_dict[dataset]['micro_f1'])\n","            overall_result[dataset]['mcc_scores'].append(eval_dict[dataset]['mcc'])\n","\n","            accuracy_scores.append(eval_dict[dataset]['accuracy'])\n","            f1_macro_scores.append(eval_dict[dataset]['macro_f1'])\n","            f1_micro_scores.append(eval_dict[dataset]['micro_f1'])\n","            mcc_scores.append(eval_dict[dataset]['mcc'])\n","            \n","            new_entry= pd.DataFrame({\n","            #data_spike_exec_1_split_dict[dataset][dataset + \"_\" + str(i+1) + \"_\" + session_id_for_df] = {\n","                #\"name\": [session_id_for_df],\n","                \"accuracy\": [eval_dict[dataset]['accuracy']],\n","                \"macro f1\": [eval_dict[dataset]['macro_f1']],\n","                \"micro_f1\": [eval_dict[dataset]['micro_f1']],\n","                \"mcc\": [eval_dict[dataset]['mcc']],\n","                \"config\": [str(config)],\n","                \"config_activation\": [str(config[\"activation\"])],\n","                \"config_learning_rate\": [str(config[\"learning_rate\"])],\n","                \"config_number_shared_hidden_layers\": [str(len(config[\"shared_hidden_layers\"]))],\n","                \"config_shared_hidden_layers\": [str(config[\"shared_hidden_layers\"])],\n","                \"config_number_a2_hidden_layers\": [str(len(config[\"a2_output_hidden_layers\"]))],\n","                \"config_a2_hidden_layers\": [str(config[\"a2_output_hidden_layers\"])],\n","                \"config_number_a3_hidden_layers\": [str(len(config[\"a3_output_hidden_layers\"]))],\n","                \"config_a3_hidden_layers\": [str(config[\"a3_output_hidden_layers\"])],\n","                \"config_number_a4_hidden_layers\": [str(len(config[\"a4_output_hidden_layers\"]))],\n","                \"config_a4_hidden_layers\": [str(config[\"a4_output_hidden_layers\"])],\n","                \"config_number_a12_hidden_layers\": [str(len(config[\"a12_output_hidden_layers\"]))],\n","                \"config_a12_hidden_layers\": [str(config[\"a12_output_hidden_layers\"])],\n","                \"config_number_a21_hidden_layers\": [str(len(config[\"a21_output_hidden_layers\"]))],\n","                \"config_a21_hidden_layers\": [str(config[\"a21_output_hidden_layers\"])],\n","                \"config_epochs\": [str(config[\"epochs\"])],\n","                \"config_batch_size\": [str(config[\"batch_size\"])],\n","                \"config_dropout_rate\": [str(config[\"dropout_rate\"])],\n","            })\n","\n","            if i == 0:\n","                df_data_spike_1_split[dataset] = new_entry\n","            else:\n","                df_data_spike_1_split[dataset]= pd.concat([df_data_spike_1_split[dataset], new_entry], ignore_index=True, axis=0)\n","\n","\n","    \n","    for dataset in overall_result.keys():\n","\n","        #data_spike_exec_full_split_dict[dataset][dataset + \"_\" + session_id_for_df] = {\n","        new_data_spike_exec_full_split_dict = pd.DataFrame({\n","                #\"name\" : [session_id_for_df],\n","\n","                \"config_activation\": [str(config[\"activation\"])],\n","                \"config_learning_rate\": [str(config[\"learning_rate\"])],\n","                \"config_number_shared_hidden_layers\": [str(len(config[\"shared_hidden_layers\"]))],\n","                \"config_shared_hidden_layers\": [str(config[\"shared_hidden_layers\"])],\n","                \"config_number_a2_hidden_layers\": [str(len(config[\"a2_output_hidden_layers\"]))],\n","                \"config_a2_hidden_layers\": [str(config[\"a2_output_hidden_layers\"])],\n","                \"config_number_a3_hidden_layers\": [str(len(config[\"a3_output_hidden_layers\"]))],\n","                \"config_a3_hidden_layers\": [str(config[\"a3_output_hidden_layers\"])],\n","                \"config_number_a4_hidden_layers\": [str(len(config[\"a4_output_hidden_layers\"]))],\n","                \"config_a4_hidden_layers\": [str(config[\"a4_output_hidden_layers\"])],\n","                \"config_number_a12_hidden_layers\": [str(len(config[\"a12_output_hidden_layers\"]))],\n","                \"config_a12_hidden_layers\": [str(config[\"a12_output_hidden_layers\"])],\n","                \"config_number_a21_hidden_layers\": [str(len(config[\"a21_output_hidden_layers\"]))],\n","                \"config_a21_hidden_layers\": [str(config[\"a21_output_hidden_layers\"])],\n","                \"config_epochs\": [str(config[\"epochs\"])],\n","                \"config_batch_size\": [str(config[\"batch_size\"])],\n","                \"config_dropout_rate\": [str(config[\"dropout_rate\"])],\n","\n","                \"mean_accuracy\": [np.mean(overall_result[dataset]['accuracy_scores'])],\n","                \"std_accuracy\": [np.std(overall_result[dataset]['accuracy_scores'])],\n","                \"min_accuracy\": [min(overall_result[dataset]['accuracy_scores'])],\n","                \"max_accuracy\": [max(overall_result[dataset]['accuracy_scores'])],\n","\n","                \"mean_f1_macro\": [np.mean(overall_result[dataset]['f1_macro_scores'])],\n","                \"min_f1_macro\": [min(overall_result[dataset]['f1_macro_scores'])],\n","                \"max_f1_macro\": [max(overall_result[dataset]['f1_macro_scores'])],\n","                \"std_f1_macro\": [np.std(overall_result[dataset]['f1_macro_scores'])],\n","\n","                \"mean_f1_micro\": [np.mean(overall_result[dataset]['f1_micro_scores'])],\n","                \"min_f1_micro\": [min(overall_result[dataset]['f1_micro_scores'])],\n","                \"max_f1_micro\": [max(overall_result[dataset]['f1_micro_scores'])],\n","                \"std_f1_micro\": [np.std(overall_result[dataset]['f1_micro_scores'])],\n","\n","                \"mean_mcc\": [np.mean(overall_result[dataset]['mcc_scores'])],\n","                \"std_mcc\": [np.std(overall_result[dataset]['mcc_scores'])],\n","                \"min_mcc\": [min(overall_result[dataset]['mcc_scores'])],\n","                \"max_mcc\": [max(overall_result[dataset]['mcc_scores'])],\n","\n","                \"config\": [str(config)]\n","                \n","        })\n","\n","        full_split_path = os.path.join(helper.results_dir, f'Feature_based/optimize_model_for_a12_tune_for_avg_acc/{dataset}.pkl')\n","        if os.path.exists(full_split_path):\n","            df_existing_full = pd.read_pickle(full_split_path)\n","            df_data_spike_full_split = pd.concat([df_existing_full, new_data_spike_exec_full_split_dict], ignore_index=True, axis=0)\n","        else:\n","            print(f\"No existing full split data found at {full_split_path}, creating new file.\")\n","            df_data_spike_full_split = new_data_spike_exec_full_split_dict\n","        \n","        # Save the updated full split data to file\n","        df_data_spike_full_split.to_pickle(full_split_path)\n","\n","\n","        # Save the 1 split data using the full path\n","        split_path = os.path.join(helper.results_dir, f'Feature_based/optimize_model_for_a12_tune_for_avg_acc/{dataset}_single_split.pkl')\n","        if os.path.exists(split_path):\n","            df_existing_1_spike = pd.read_pickle(split_path)\n","            df_data_spike_1_split[dataset] = pd.concat([df_data_spike_1_split[dataset], df_existing_1_spike], ignore_index=True, axis=0)\n","        else:\n","            print(f\"No existing 1 split data found at {split_path}, creating new file\")\n","\n","        # Save the updated 1 split data to file\n","        df_data_spike_1_split[dataset].to_pickle(split_path)\n","\n","    if np.min(accuracy_scores) == 0:\n","        print(f\"Zero accuracy detected in config: {config}\")\n","        print(f\"Accuracy scores: {accuracy_scores}\")\n","\n","    session.report({\n","        \"mean_accuracy_a12\": np.mean(overall_result['a12']['accuracy_scores']),\n","        \"mean_mean_accuracy\": np.mean(accuracy_scores)\n","    })"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def generate_hidden_layers_config(min_layers=1, max_layers=5, min_nodes=10, max_nodes=50, step=10):\n","    possible_layers = []\n","\n","    for num_layers in range(min_layers, max_layers + 1):\n","\n","        shared_layers = list(itertools.product(range(min_nodes, max_nodes + 1, step), repeat=num_layers))\n","\n","        max_output_layers = max_layers - num_layers\n","        \n","        output_layers = []\n","        for num_output_layers in range(0, max_output_layers + 1):\n","\n","            output_layers = list(itertools.product(range(min_nodes, max_nodes + 1, step), repeat=num_output_layers))\n","\n","        possible_layers.append({'shared': shared_layers, 'output': {'a2': output_layers, 'a3': output_layers, 'a4': output_layers, 'a12': output_layers, 'a21': output_layers}})\n","\n","    return possible_layers"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def five_fold_cross_validation(num_layers_shared, num_layers_individual):\n","\n","    #num_layers = num_layers - 1\n","\n","    global best_params_list_getting\n","\n","    shared_hidden_layers_options = list(itertools.product(range(10, 50 + 1, 10), repeat=num_layers_shared))\n","    individual_hidden_layers_options = list(itertools.product(range(10, 50 + 1, 10), repeat=num_layers_individual))\n","\n","\n","    config = {\n","        \"activation\": tune.choice([\"relu\", \"tanh\", \"sigmoid\"]),\n","        \"learning_rate\": tune.loguniform(1e-4, 1e-2),\n","        \"batch_size\": tune.choice([32, 64, 128]),\n","        \"shared_hidden_layers\": tune.choice(shared_hidden_layers_options),\n","        \"a2_output_hidden_layers\": tune.choice(individual_hidden_layers_options),\n","        \"a3_output_hidden_layers\": tune.choice(individual_hidden_layers_options),\n","        \"a4_output_hidden_layers\": tune.choice(individual_hidden_layers_options),\n","        \"a12_output_hidden_layers\": tune.choice(individual_hidden_layers_options),\n","        \"a21_output_hidden_layers\": tune.choice(individual_hidden_layers_options),\n","        \"epochs\": tune.choice([30, 40, 50,60]),\n","        \"dropout_rate\": tune.uniform(0.2, 0.5)\n","    }\n","    \n","    scheduler = ASHAScheduler(\n","        metric=\"mean_mean_accuracy\",\n","        mode=\"max\",\n","        max_t=10,\n","        grace_period=1,\n","        reduction_factor=2\n","    )\n","    \n","    search_alg = OptunaSearch(metric=\"mean_mean_accuracy\", mode=\"max\")\n","    \n","    analysis = tune.run(\n","        tune.with_parameters(train_and_evaluate),\n","        resources_per_trial={\"cpu\": 12, \"gpu\": 1, \"accelerator_type:RTX\": 1},\n","        config=config,\n","        scheduler=scheduler,\n","        search_alg=search_alg,\n","        num_samples=32,\n","        verbose=1,\n","        storage_path=helper.ray_results_dir,\n","        trial_dirname_creator=custom_trial_dirname\n","    )\n","\n","    best_config_data_ray_tune = analysis.get_best_config(metric=\"mean_accuracy_a12\", mode=\"max\")\n","    print(\"Best hyperparameters found were: \", best_config_data_ray_tune)\n","    best_params_list_getting.append(best_config_data_ray_tune)\n","    \n","    return analysis"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div class=\"tuneStatus\">\n","  <div style=\"display: flex;flex-direction: row\">\n","    <div style=\"display: flex;flex-direction: column;\">\n","      <h3>Tune Status</h3>\n","      <table>\n","<tbody>\n","<tr><td>Current time:</td><td>2024-09-01 21:50:51</td></tr>\n","<tr><td>Running for: </td><td>00:15:18.28        </td></tr>\n","<tr><td>Memory:      </td><td>3.6/15.4 GiB       </td></tr>\n","</tbody>\n","</table>\n","    </div>\n","    <div class=\"vDivider\"></div>\n","    <div class=\"systemInfo\">\n","      <h3>System Info</h3>\n","      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.515896518358998<br>Logical resource usage: 12.0/12 CPUs, 1.0/1 GPUs (1.0/1.0 accelerator_type:RTX)\n","    </div>\n","    \n","  </div>\n","  <div class=\"hDivider\"></div>\n","  <div class=\"trialStatus\">\n","    <h3>Trial Status</h3>\n","    <table>\n","<thead>\n","<tr><th>Trial name                 </th><th>status    </th><th>loc                </th><th>a12_output_hidden_la\n","yers                 </th><th>a21_output_hidden_la\n","yers                 </th><th>a2_output_hidden_lay\n","ers                 </th><th>a3_output_hidden_lay\n","ers                 </th><th>a4_output_hidden_lay\n","ers                 </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  mean_accuracy_a12</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n","</thead>\n","<tbody>\n","<tr><td>train_and_evaluate_000797c7</td><td>TERMINATED</td><td>172.27.13.81:176173</td><td>(20, 50, 20, 50)</td><td>(10, 50, 30, 50)</td><td>(50, 10, 10, 50)</td><td>(10, 30, 20, 50)</td><td>(40, 40, 10, 40)</td><td>sigmoid     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.30864 </td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00155313 </td><td>(20, 20, 40, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.6928</td><td style=\"text-align: right;\">           0.164602</td><td style=\"text-align: right;\">            0.412289</td></tr>\n","<tr><td>train_and_evaluate_03aefa50</td><td>TERMINATED</td><td>172.27.13.81:176409</td><td>(10, 50, 40, 10)</td><td>(30, 30, 30, 50)</td><td>(40, 50, 20, 30)</td><td>(20, 50, 30, 10)</td><td>(40, 50, 10, 20)</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.330218</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000239268</td><td>(20, 20, 20, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         37.9269</td><td style=\"text-align: right;\">           0.171837</td><td style=\"text-align: right;\">            0.425686</td></tr>\n","<tr><td>train_and_evaluate_d5777ccf</td><td>TERMINATED</td><td>172.27.13.81:176712</td><td>(30, 30, 40, 10)</td><td>(40, 50, 20, 20)</td><td>(20, 50, 20, 10)</td><td>(40, 20, 10, 10)</td><td>(30, 20, 50, 40)</td><td>sigmoid     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.394016</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">    0.00820538 </td><td>(50, 50, 20, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         20.9825</td><td style=\"text-align: right;\">           0.165123</td><td style=\"text-align: right;\">            0.411459</td></tr>\n","<tr><td>train_and_evaluate_db004056</td><td>TERMINATED</td><td>172.27.13.81:176942</td><td>(40, 10, 20, 40)</td><td>(30, 50, 10, 10)</td><td>(10, 10, 10, 40)</td><td>(20, 30, 50, 50)</td><td>(10, 30, 40, 20)</td><td>sigmoid     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.45327 </td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00171567 </td><td>(40, 10, 30, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.0365</td><td style=\"text-align: right;\">           0.160445</td><td style=\"text-align: right;\">            0.412931</td></tr>\n","<tr><td>train_and_evaluate_b0b0acfd</td><td>TERMINATED</td><td>172.27.13.81:177160</td><td>(50, 10, 20, 30)</td><td>(20, 20, 40, 20)</td><td>(10, 20, 30, 50)</td><td>(20, 10, 50, 20)</td><td>(50, 40, 50, 30)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.422198</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">    0.00496833 </td><td>(10, 40, 10, 30)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         54.0793</td><td style=\"text-align: right;\">           0.173896</td><td style=\"text-align: right;\">            0.457584</td></tr>\n","<tr><td>train_and_evaluate_16cf4cca</td><td>TERMINATED</td><td>172.27.13.81:177536</td><td>(20, 40, 30, 40)</td><td>(10, 50, 50, 40)</td><td>(30, 10, 30, 50)</td><td>(30, 10, 30, 30)</td><td>(30, 50, 30, 50)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.280307</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00113024 </td><td>(40, 30, 10, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.7907</td><td style=\"text-align: right;\">           0.206002</td><td style=\"text-align: right;\">            0.559211</td></tr>\n","<tr><td>train_and_evaluate_eb92a3b4</td><td>TERMINATED</td><td>172.27.13.81:177771</td><td>(20, 50, 30, 30)</td><td>(30, 50, 50, 30)</td><td>(10, 20, 40, 40)</td><td>(40, 40, 40, 40)</td><td>(40, 30, 10, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.414151</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000436909</td><td>(50, 20, 10, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         16.8061</td><td style=\"text-align: right;\">           0.15787 </td><td style=\"text-align: right;\">            0.410708</td></tr>\n","<tr><td>train_and_evaluate_ce9cbc20</td><td>TERMINATED</td><td>172.27.13.81:177983</td><td>(30, 10, 50, 30)</td><td>(30, 40, 10, 30)</td><td>(10, 10, 10, 50)</td><td>(40, 30, 30, 40)</td><td>(20, 20, 10, 40)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.410524</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000664066</td><td>(20, 40, 50, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         44.6296</td><td style=\"text-align: right;\">           0.180135</td><td style=\"text-align: right;\">            0.445704</td></tr>\n","<tr><td>train_and_evaluate_44e8962e</td><td>TERMINATED</td><td>172.27.13.81:178319</td><td>(20, 30, 40, 10)</td><td>(40, 50, 30, 50)</td><td>(50, 50, 30, 40)</td><td>(20, 30, 30, 40)</td><td>(40, 10, 30, 50)</td><td>sigmoid     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.407008</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00313869 </td><td>(10, 10, 30, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.7733</td><td style=\"text-align: right;\">           0.167706</td><td style=\"text-align: right;\">            0.416278</td></tr>\n","<tr><td>train_and_evaluate_d6bf8049</td><td>TERMINATED</td><td>172.27.13.81:178517</td><td>(40, 10, 50, 20)</td><td>(50, 30, 30, 10)</td><td>(20, 20, 40, 40)</td><td>(10, 20, 20, 20)</td><td>(50, 10, 10, 30)</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.267724</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00102666 </td><td>(30, 40, 20, 30)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.6003</td><td style=\"text-align: right;\">           0.165123</td><td style=\"text-align: right;\">            0.387009</td></tr>\n","<tr><td>train_and_evaluate_2d0f6859</td><td>TERMINATED</td><td>172.27.13.81:178776</td><td>(50, 10, 10, 10)</td><td>(20, 20, 40, 10)</td><td>(20, 50, 10, 10)</td><td>(40, 40, 30, 40)</td><td>(50, 50, 20, 40)</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.207568</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00017514 </td><td>(20, 40, 10, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.2294</td><td style=\"text-align: right;\">           0.180157</td><td style=\"text-align: right;\">            0.518129</td></tr>\n","<tr><td>train_and_evaluate_76c2d157</td><td>TERMINATED</td><td>172.27.13.81:179035</td><td>(50, 40, 30, 10)</td><td>(20, 50, 20, 50)</td><td>(30, 50, 50, 20)</td><td>(30, 20, 30, 30)</td><td>(10, 30, 20, 30)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.205186</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000194847</td><td>(30, 30, 20, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.7799</td><td style=\"text-align: right;\">           0.195119</td><td style=\"text-align: right;\">            0.534067</td></tr>\n","<tr><td>train_and_evaluate_86754bff</td><td>TERMINATED</td><td>172.27.13.81:179269</td><td>(20, 10, 20, 10)</td><td>(40, 50, 50, 20)</td><td>(30, 20, 40, 40)</td><td>(40, 30, 10, 20)</td><td>(50, 40, 10, 20)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.200607</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000109888</td><td>(20, 50, 10, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.0908</td><td style=\"text-align: right;\">           0.202923</td><td style=\"text-align: right;\">            0.560022</td></tr>\n","<tr><td>train_and_evaluate_6caaea97</td><td>TERMINATED</td><td>172.27.13.81:179503</td><td>(20, 40, 30, 40)</td><td>(50, 50, 10, 20)</td><td>(30, 20, 50, 20)</td><td>(20, 20, 30, 20)</td><td>(30, 20, 40, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.200576</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000127841</td><td>(30, 20, 30, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         21.4681</td><td style=\"text-align: right;\">           0.210675</td><td style=\"text-align: right;\">            0.554923</td></tr>\n","<tr><td>train_and_evaluate_0153f0e1</td><td>TERMINATED</td><td>172.27.13.81:179733</td><td>(30, 10, 10, 40)</td><td>(10, 50, 20, 10)</td><td>(20, 20, 20, 40)</td><td>(30, 50, 10, 20)</td><td>(30, 40, 20, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.261935</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000115078</td><td>(40, 40, 10, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.7245</td><td style=\"text-align: right;\">           0.222564</td><td style=\"text-align: right;\">            0.57289 </td></tr>\n","<tr><td>train_and_evaluate_bba91a47</td><td>TERMINATED</td><td>172.27.13.81:179968</td><td>(40, 50, 20, 10)</td><td>(20, 20, 20, 10)</td><td>(10, 10, 40, 20)</td><td>(30, 30, 20, 50)</td><td>(40, 20, 20, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.258808</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000386841</td><td>(50, 20, 30, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.8281</td><td style=\"text-align: right;\">           0.188912</td><td style=\"text-align: right;\">            0.552442</td></tr>\n","<tr><td>train_and_evaluate_4c24f2c3</td><td>TERMINATED</td><td>172.27.13.81:180206</td><td>(30, 30, 40, 40)</td><td>(10, 50, 20, 10)</td><td>(20, 40, 40, 40)</td><td>(50, 10, 50, 30)</td><td>(30, 10, 50, 50)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.255665</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000106635</td><td>(40, 40, 10, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.6015</td><td style=\"text-align: right;\">           0.216355</td><td style=\"text-align: right;\">            0.568767</td></tr>\n","<tr><td>train_and_evaluate_079ae9d0</td><td>TERMINATED</td><td>172.27.13.81:180444</td><td>(20, 10, 20, 10)</td><td>(50, 30, 30, 30)</td><td>(30, 10, 40, 20)</td><td>(30, 40, 40, 40)</td><td>(20, 50, 30, 40)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.236599</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000108356</td><td>(40, 20, 50, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.2996</td><td style=\"text-align: right;\">           0.176498</td><td style=\"text-align: right;\">            0.568766</td></tr>\n","<tr><td>train_and_evaluate_bb3c976d</td><td>TERMINATED</td><td>172.27.13.81:180677</td><td>(50, 40, 40, 10)</td><td>(50, 50, 50, 20)</td><td>(20, 10, 20, 10)</td><td>(30, 50, 20, 20)</td><td>(20, 40, 40, 40)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.355916</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000324683</td><td>(50, 10, 10, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         21.9893</td><td style=\"text-align: right;\">           0.173392</td><td style=\"text-align: right;\">            0.449783</td></tr>\n","<tr><td>train_and_evaluate_927b19e5</td><td>TERMINATED</td><td>172.27.13.81:180913</td><td>(40, 50, 40, 30)</td><td>(10, 30, 40, 20)</td><td>(20, 20, 30, 30)</td><td>(50, 50, 10, 40)</td><td>(50, 30, 40, 20)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.361403</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">    0.000297524</td><td>(20, 50, 50, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         34.545 </td><td style=\"text-align: right;\">           0.193077</td><td style=\"text-align: right;\">            0.504787</td></tr>\n","<tr><td>train_and_evaluate_a75ea372</td><td>TERMINATED</td><td>172.27.13.81:181200</td><td>(30, 30, 40, 40)</td><td>(20, 50, 30, 30)</td><td>(40, 30, 20, 40)</td><td>(30, 30, 50, 40)</td><td>(10, 20, 30, 40)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.495269</td><td style=\"text-align: right;\">      60</td><td style=\"text-align: right;\">    0.000555439</td><td>(10, 30, 30, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         31.2954</td><td style=\"text-align: right;\">           0.174425</td><td style=\"text-align: right;\">            0.446921</td></tr>\n","<tr><td>train_and_evaluate_769bcfcd</td><td>TERMINATED</td><td>172.27.13.81:181474</td><td>(50, 30, 20, 50)</td><td>(30, 20, 20, 50)</td><td>(40, 50, 10, 40)</td><td>(40, 40, 10, 50)</td><td>(10, 40, 20, 30)</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.493137</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000537576</td><td>(10, 40, 40, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.6329</td><td style=\"text-align: right;\">           0.153733</td><td style=\"text-align: right;\">            0.427872</td></tr>\n","<tr><td>train_and_evaluate_fc912ff4</td><td>TERMINATED</td><td>172.27.13.81:181698</td><td>(50, 20, 20, 50)</td><td>(10, 50, 20, 10)</td><td>(10, 20, 30, 40)</td><td>(20, 50, 20, 30)</td><td>(30, 40, 20, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.241548</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000101894</td><td>(40, 30, 30, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.1066</td><td style=\"text-align: right;\">           0.215849</td><td style=\"text-align: right;\">            0.56504 </td></tr>\n","<tr><td>train_and_evaluate_1d9ad0f4</td><td>TERMINATED</td><td>172.27.13.81:181936</td><td>(50, 40, 10, 40)</td><td>(50, 50, 40, 40)</td><td>(20, 40, 40, 40)</td><td>(50, 20, 50, 50)</td><td>(30, 10, 50, 50)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.246785</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000108624</td><td>(20, 10, 50, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         25.2028</td><td style=\"text-align: right;\">           0.19977 </td><td style=\"text-align: right;\">            0.538275</td></tr>\n","<tr><td>train_and_evaluate_b86c80a3</td><td>TERMINATED</td><td>172.27.13.81:182183</td><td>(50, 20, 50, 30)</td><td>(10, 50, 20, 10)</td><td>(10, 40, 30, 50)</td><td>(40, 20, 10, 40)</td><td>(40, 20, 40, 20)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.235091</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000162327</td><td>(50, 20, 50, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.6229</td><td style=\"text-align: right;\">           0.194599</td><td style=\"text-align: right;\">            0.569101</td></tr>\n","<tr><td>train_and_evaluate_05989105</td><td>TERMINATED</td><td>172.27.13.81:182427</td><td>(20, 40, 30, 20)</td><td>(10, 50, 20, 10)</td><td>(40, 50, 20, 40)</td><td>(20, 30, 30, 30)</td><td>(30, 50, 20, 20)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.290281</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000176368</td><td>(40, 20, 50, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.5236</td><td style=\"text-align: right;\">           0.219479</td><td style=\"text-align: right;\">            0.558567</td></tr>\n","<tr><td>train_and_evaluate_592b6628</td><td>TERMINATED</td><td>172.27.13.81:182668</td><td>(20, 20, 30, 10)</td><td>(30, 50, 20, 50)</td><td>(20, 10, 20, 20)</td><td>(40, 20, 10, 40)</td><td>(20, 10, 50, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.302046</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00016459 </td><td>(30, 30, 20, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.7963</td><td style=\"text-align: right;\">           0.193063</td><td style=\"text-align: right;\">            0.463266</td></tr>\n","<tr><td>train_and_evaluate_ab77ac73</td><td>TERMINATED</td><td>172.27.13.81:182908</td><td>(50, 30, 20, 20)</td><td>(40, 50, 50, 10)</td><td>(20, 20, 20, 50)</td><td>(20, 40, 10, 20)</td><td>(20, 10, 40, 20)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.308464</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00015222 </td><td>(40, 50, 10, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.4268</td><td style=\"text-align: right;\">           0.218429</td><td style=\"text-align: right;\">            0.52971 </td></tr>\n","<tr><td>train_and_evaluate_a8bbeea4</td><td>TERMINATED</td><td>172.27.13.81:183145</td><td>(20, 40, 30, 50)</td><td>(30, 20, 30, 40)</td><td>(10, 40, 30, 50)</td><td>(50, 30, 30, 30)</td><td>(20, 20, 10, 20)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.228997</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000256096</td><td>(30, 10, 30, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.5567</td><td style=\"text-align: right;\">           0.205982</td><td style=\"text-align: right;\">            0.544437</td></tr>\n","<tr><td>train_and_evaluate_b2816c01</td><td>TERMINATED</td><td>172.27.13.81:183384</td><td>(40, 40, 40, 30)</td><td>(30, 50, 10, 40)</td><td>(20, 50, 30, 40)</td><td>(30, 10, 30, 10)</td><td>(10, 30, 10, 40)</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.226901</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000232701</td><td>(50, 30, 10, 30)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.43  </td><td style=\"text-align: right;\">           0.197226</td><td style=\"text-align: right;\">            0.559027</td></tr>\n","<tr><td>train_and_evaluate_d398109d</td><td>TERMINATED</td><td>172.27.13.81:183601</td><td>(30, 50, 50, 30)</td><td>(10, 50, 20, 10)</td><td>(40, 50, 10, 50)</td><td>(40, 20, 50, 30)</td><td>(30, 10, 10, 50)</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.322007</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000221098</td><td>(40, 10, 40, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.8295</td><td style=\"text-align: right;\">           0.19307 </td><td style=\"text-align: right;\">            0.513664</td></tr>\n","<tr><td>train_and_evaluate_0f5188c5</td><td>TERMINATED</td><td>172.27.13.81:183817</td><td>(50, 40, 30, 30)</td><td>(20, 30, 30, 10)</td><td>(20, 20, 50, 50)</td><td>(20, 50, 20, 10)</td><td>(30, 50, 40, 40)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.324408</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00201031 </td><td>(40, 40, 10, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.2943</td><td style=\"text-align: right;\">           0.177543</td><td style=\"text-align: right;\">            0.462984</td></tr>\n","</tbody>\n","</table>\n","  </div>\n","</div>\n","<style>\n",".tuneStatus {\n","  color: var(--jp-ui-font-color1);\n","}\n",".tuneStatus .systemInfo {\n","  display: flex;\n","  flex-direction: column;\n","}\n",".tuneStatus td {\n","  white-space: nowrap;\n","}\n",".tuneStatus .trialStatus {\n","  display: flex;\n","  flex-direction: column;\n","}\n",".tuneStatus h3 {\n","  font-weight: bold;\n","}\n",".tuneStatus .hDivider {\n","  border-bottom-width: var(--jp-border-width);\n","  border-bottom-color: var(--jp-border-color0);\n","  border-bottom-style: solid;\n","}\n",".tuneStatus .vDivider {\n","  border-left-width: var(--jp-border-width);\n","  border-left-color: var(--jp-border-color0);\n","  border-left-style: solid;\n","  margin: 0.5em 1em 0.5em 1em;\n","}\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-09-01 21:35:58,524\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 20, 40, 50), 'a2_output_hidden_layers': (50, 10, 10, 50), 'a3_output_hidden_layers': (10, 30, 20, 50), 'a4_output_hidden_layers': (40, 40, 10, 40), 'a12_output_hidden_layers': (20, 50, 20, 50), 'a21_output_hidden_layers': (10, 50, 30, 50)}\n","2024-09-01 21:36:40,017\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 20, 20, 40), 'a2_output_hidden_layers': (40, 50, 20, 30), 'a3_output_hidden_layers': (20, 50, 30, 10), 'a4_output_hidden_layers': (40, 50, 10, 20), 'a12_output_hidden_layers': (10, 50, 40, 10), 'a21_output_hidden_layers': (30, 30, 30, 50)}\n","2024-09-01 21:37:05,133\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 50, 20, 20), 'a2_output_hidden_layers': (20, 50, 20, 10), 'a3_output_hidden_layers': (40, 20, 10, 10), 'a4_output_hidden_layers': (30, 20, 50, 40), 'a12_output_hidden_layers': (30, 30, 40, 10), 'a21_output_hidden_layers': (40, 50, 20, 20)}\n","2024-09-01 21:37:25,949\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 10, 30, 40), 'a2_output_hidden_layers': (10, 10, 10, 40), 'a3_output_hidden_layers': (20, 30, 50, 50), 'a4_output_hidden_layers': (10, 30, 40, 20), 'a12_output_hidden_layers': (40, 10, 20, 40), 'a21_output_hidden_layers': (30, 50, 10, 10)}\n","2024-09-01 21:38:24,111\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 40, 10, 30), 'a2_output_hidden_layers': (10, 20, 30, 50), 'a3_output_hidden_layers': (20, 10, 50, 20), 'a4_output_hidden_layers': (50, 40, 50, 30), 'a12_output_hidden_layers': (50, 10, 20, 30), 'a21_output_hidden_layers': (20, 20, 40, 20)}\n","2024-09-01 21:38:50,727\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 30, 10, 40), 'a2_output_hidden_layers': (30, 10, 30, 50), 'a3_output_hidden_layers': (30, 10, 30, 30), 'a4_output_hidden_layers': (30, 50, 30, 50), 'a12_output_hidden_layers': (20, 40, 30, 40), 'a21_output_hidden_layers': (10, 50, 50, 40)}\n","2024-09-01 21:39:10,843\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20, 10, 10), 'a2_output_hidden_layers': (10, 20, 40, 40), 'a3_output_hidden_layers': (40, 40, 40, 40), 'a4_output_hidden_layers': (40, 30, 10, 10), 'a12_output_hidden_layers': (20, 50, 30, 30), 'a21_output_hidden_layers': (30, 50, 50, 30)}\n","2024-09-01 21:40:00,294\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 40, 50, 20), 'a2_output_hidden_layers': (10, 10, 10, 50), 'a3_output_hidden_layers': (40, 30, 30, 40), 'a4_output_hidden_layers': (20, 20, 10, 40), 'a12_output_hidden_layers': (30, 10, 50, 30), 'a21_output_hidden_layers': (30, 40, 10, 30)}\n","2024-09-01 21:40:17,704\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 10, 30, 10), 'a2_output_hidden_layers': (50, 50, 30, 40), 'a3_output_hidden_layers': (20, 30, 30, 40), 'a4_output_hidden_layers': (40, 10, 30, 50), 'a12_output_hidden_layers': (20, 30, 40, 10), 'a21_output_hidden_layers': (40, 50, 30, 50)}\n","2024-09-01 21:40:49,327\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 40, 20, 30), 'a2_output_hidden_layers': (20, 20, 40, 40), 'a3_output_hidden_layers': (10, 20, 20, 20), 'a4_output_hidden_layers': (50, 10, 10, 30), 'a12_output_hidden_layers': (40, 10, 50, 20), 'a21_output_hidden_layers': (50, 30, 30, 10)}\n","2024-09-01 21:41:21,290\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 40, 10, 20), 'a2_output_hidden_layers': (20, 50, 10, 10), 'a3_output_hidden_layers': (40, 40, 30, 40), 'a4_output_hidden_layers': (50, 50, 20, 40), 'a12_output_hidden_layers': (50, 10, 10, 10), 'a21_output_hidden_layers': (20, 20, 40, 10)}\n","2024-09-01 21:41:47,800\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 30, 20, 10), 'a2_output_hidden_layers': (30, 50, 50, 20), 'a3_output_hidden_layers': (30, 20, 30, 30), 'a4_output_hidden_layers': (10, 30, 20, 30), 'a12_output_hidden_layers': (50, 40, 30, 10), 'a21_output_hidden_layers': (20, 50, 20, 50)}\n","2024-09-01 21:42:13,014\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 50, 10, 40), 'a2_output_hidden_layers': (30, 20, 40, 40), 'a3_output_hidden_layers': (40, 30, 10, 20), 'a4_output_hidden_layers': (50, 40, 10, 20), 'a12_output_hidden_layers': (20, 10, 20, 10), 'a21_output_hidden_layers': (40, 50, 50, 20)}\n","2024-09-01 21:42:38,462\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 20, 30, 10), 'a2_output_hidden_layers': (30, 20, 50, 20), 'a3_output_hidden_layers': (20, 20, 30, 20), 'a4_output_hidden_layers': (30, 20, 40, 10), 'a12_output_hidden_layers': (20, 40, 30, 40), 'a21_output_hidden_layers': (50, 50, 10, 20)}\n","2024-09-01 21:43:04,687\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 40, 10, 50), 'a2_output_hidden_layers': (20, 20, 20, 40), 'a3_output_hidden_layers': (30, 50, 10, 20), 'a4_output_hidden_layers': (30, 40, 20, 10), 'a12_output_hidden_layers': (30, 10, 10, 40), 'a21_output_hidden_layers': (10, 50, 20, 10)}\n","2024-09-01 21:43:31,787\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20, 30, 20), 'a2_output_hidden_layers': (10, 10, 40, 20), 'a3_output_hidden_layers': (30, 30, 20, 50), 'a4_output_hidden_layers': (40, 20, 20, 10), 'a12_output_hidden_layers': (40, 50, 20, 10), 'a21_output_hidden_layers': (20, 20, 20, 10)}\n","2024-09-01 21:43:58,615\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 40, 10, 50), 'a2_output_hidden_layers': (20, 40, 40, 40), 'a3_output_hidden_layers': (50, 10, 50, 30), 'a4_output_hidden_layers': (30, 10, 50, 50), 'a12_output_hidden_layers': (30, 30, 40, 40), 'a21_output_hidden_layers': (10, 50, 20, 10)}\n","2024-09-01 21:44:24,304\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 20, 50, 40), 'a2_output_hidden_layers': (30, 10, 40, 20), 'a3_output_hidden_layers': (30, 40, 40, 40), 'a4_output_hidden_layers': (20, 50, 30, 40), 'a12_output_hidden_layers': (20, 10, 20, 10), 'a21_output_hidden_layers': (50, 30, 30, 30)}\n","2024-09-01 21:44:50,289\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 10, 10, 10), 'a2_output_hidden_layers': (20, 10, 20, 10), 'a3_output_hidden_layers': (30, 50, 20, 20), 'a4_output_hidden_layers': (20, 40, 40, 40), 'a12_output_hidden_layers': (50, 40, 40, 10), 'a21_output_hidden_layers': (50, 50, 50, 20)}\n","2024-09-01 21:45:28,895\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 50, 50, 20), 'a2_output_hidden_layers': (20, 20, 30, 30), 'a3_output_hidden_layers': (50, 50, 10, 40), 'a4_output_hidden_layers': (50, 30, 40, 20), 'a12_output_hidden_layers': (40, 50, 40, 30), 'a21_output_hidden_layers': (10, 30, 40, 20)}\n","2024-09-01 21:46:03,327\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 30, 30, 10), 'a2_output_hidden_layers': (40, 30, 20, 40), 'a3_output_hidden_layers': (30, 30, 50, 40), 'a4_output_hidden_layers': (10, 20, 30, 40), 'a12_output_hidden_layers': (30, 30, 40, 40), 'a21_output_hidden_layers': (20, 50, 30, 30)}\n","2024-09-01 21:46:25,966\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 40, 40, 10), 'a2_output_hidden_layers': (40, 50, 10, 40), 'a3_output_hidden_layers': (40, 40, 10, 50), 'a4_output_hidden_layers': (10, 40, 20, 30), 'a12_output_hidden_layers': (50, 30, 20, 50), 'a21_output_hidden_layers': (30, 20, 20, 50)}\n","2024-09-01 21:46:53,267\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 30, 30, 20), 'a2_output_hidden_layers': (10, 20, 30, 40), 'a3_output_hidden_layers': (20, 50, 20, 30), 'a4_output_hidden_layers': (30, 40, 20, 10), 'a12_output_hidden_layers': (50, 20, 20, 50), 'a21_output_hidden_layers': (10, 50, 20, 10)}\n","2024-09-01 21:47:22,420\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 10, 50, 20), 'a2_output_hidden_layers': (20, 40, 40, 40), 'a3_output_hidden_layers': (50, 20, 50, 50), 'a4_output_hidden_layers': (30, 10, 50, 50), 'a12_output_hidden_layers': (50, 40, 10, 40), 'a21_output_hidden_layers': (50, 50, 40, 40)}\n","2024-09-01 21:47:50,859\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20, 50, 10), 'a2_output_hidden_layers': (10, 40, 30, 50), 'a3_output_hidden_layers': (40, 20, 10, 40), 'a4_output_hidden_layers': (40, 20, 40, 20), 'a12_output_hidden_layers': (50, 20, 50, 30), 'a21_output_hidden_layers': (10, 50, 20, 10)}\n","2024-09-01 21:48:17,753\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 20, 50, 40), 'a2_output_hidden_layers': (40, 50, 20, 40), 'a3_output_hidden_layers': (20, 30, 30, 30), 'a4_output_hidden_layers': (30, 50, 20, 20), 'a12_output_hidden_layers': (20, 40, 30, 20), 'a21_output_hidden_layers': (10, 50, 20, 10)}\n","2024-09-01 21:48:45,170\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 30, 20, 20), 'a2_output_hidden_layers': (20, 10, 20, 20), 'a3_output_hidden_layers': (40, 20, 10, 40), 'a4_output_hidden_layers': (20, 10, 50, 10), 'a12_output_hidden_layers': (20, 20, 30, 10), 'a21_output_hidden_layers': (30, 50, 20, 50)}\n","2024-09-01 21:49:12,197\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 50, 10, 50), 'a2_output_hidden_layers': (20, 20, 20, 50), 'a3_output_hidden_layers': (20, 40, 10, 20), 'a4_output_hidden_layers': (20, 10, 40, 20), 'a12_output_hidden_layers': (50, 30, 20, 20), 'a21_output_hidden_layers': (40, 50, 50, 10)}\n","2024-09-01 21:49:38,873\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 10, 30, 10), 'a2_output_hidden_layers': (10, 40, 30, 50), 'a3_output_hidden_layers': (50, 30, 30, 30), 'a4_output_hidden_layers': (20, 20, 10, 20), 'a12_output_hidden_layers': (20, 40, 30, 50), 'a21_output_hidden_layers': (30, 20, 30, 40)}\n","2024-09-01 21:50:00,748\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 30, 10, 30), 'a2_output_hidden_layers': (20, 50, 30, 40), 'a3_output_hidden_layers': (30, 10, 30, 10), 'a4_output_hidden_layers': (10, 30, 10, 40), 'a12_output_hidden_layers': (40, 40, 40, 30), 'a21_output_hidden_layers': (30, 50, 10, 40)}\n","2024-09-01 21:50:22,295\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 10, 40, 40), 'a2_output_hidden_layers': (40, 50, 10, 50), 'a3_output_hidden_layers': (40, 20, 50, 30), 'a4_output_hidden_layers': (30, 10, 10, 50), 'a12_output_hidden_layers': (30, 50, 50, 30), 'a21_output_hidden_layers': (10, 50, 20, 10)}\n","2024-09-01 21:50:48,567\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 40, 10, 50), 'a2_output_hidden_layers': (20, 20, 50, 50), 'a3_output_hidden_layers': (20, 50, 20, 10), 'a4_output_hidden_layers': (30, 50, 40, 40), 'a12_output_hidden_layers': (50, 40, 30, 30), 'a21_output_hidden_layers': (20, 30, 30, 10)}\n","2024-09-01 21:50:51,250\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/mnt/c/Users/Mayra Elwes/Documents/MyWork/Multi-Task-Learning/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-09-01_21-35-32' in 2.6805s.\n","2024-09-01 21:50:51,262\tINFO tune.py:1041 -- Total run time: 918.34 seconds (915.60 seconds for the tuning loop).\n"]},{"name":"stdout","output_type":"stream","text":["Best hyperparameters found were:  {'activation': 'tanh', 'learning_rate': 0.0001150777969269492, 'batch_size': 64, 'shared_hidden_layers': (40, 40, 10, 50), 'a2_output_hidden_layers': (20, 20, 20, 40), 'a3_output_hidden_layers': (30, 50, 10, 20), 'a4_output_hidden_layers': (30, 40, 20, 10), 'a12_output_hidden_layers': (30, 10, 10, 40), 'a21_output_hidden_layers': (10, 50, 20, 10), 'epochs': 40, 'dropout_rate': 0.261934856510922}\n"]}],"source":["for i in range(5):\n","    print(f\"number of shared layers: {i}\")\n","    for j in range(5):\n","        print(f\"number of individual layers: {j}\")\n","        analysis = five_fold_cross_validation(i, j)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["df_dict_A2 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A2.pkl\")\n","df_dict_A3 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A3.pkl\")\n","df_dict_A4 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A4.pkl\")\n","df_dict_A12 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A12.pkl\")\n","df_dict_A21 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A21.pkl\")\n","\n","df_dict = pd.concat([df_dict_A2, df_dict_A3, df_dict_A4, df_dict_A12, df_dict_A21])\n","\n","df_dict = df_dict.loc[:,~df_dict.columns.duplicated()].copy()\n","df_dict = df_dict.drop_duplicates()\n","\n","df_dict.to_csv('outputs/Feature_based/mtl_fnn/Feature_based_one_split_metrics_system.csv')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-07-10T11:21:36.163810Z","iopub.status.busy":"2024-07-10T11:21:36.161935Z","iopub.status.idle":"2024-07-10T11:21:36.173402Z","shell.execute_reply":"2024-07-10T11:21:36.172464Z","shell.execute_reply.started":"2024-07-10T11:21:36.163737Z"},"trusted":true},"outputs":[],"source":["df_dict_full_A2 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A2.pkl\")\n","df_dict_full_A3 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A3.pkl\")\n","df_dict_full_A4 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A4.pkl\")\n","df_dict_full_A12 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A12.pkl\")\n","df_dict_full_A21 = pd.read_pickle(\"results/Feature_based/optimize_model_for_a12_tune_for_avg_acc/A21.pkl\")\n","\n","# remove any columns with \"config!\" in the name\n","df_dict_A3 = df_dict_full_A3.loc[:,~df_dict_full_A3.columns.str.contains('config')].copy()\n","df_dict_A4 = df_dict_full_A4.loc[:,~df_dict_full_A4.columns.str.contains('config')].copy()\n","df_dict_A12 = df_dict_full_A12.loc[:,~df_dict_full_A12.columns.str.contains('config')].copy()\n","df_dict_A21 = df_dict_full_A21.loc[:,~df_dict_full_A21.columns.str.contains('config')].copy()\n","\n","# for a2 add the suffix '_a2' to all following columns: mean_accuracy\tstd_accuracy\tmin_accuracy\tmax_accuracy\tmean_f1_macro\tmin_f1_macro\tmax_f1_macro\tstd_f1_macro\tmean_f1_micro\tmin_f1_micro\tmax_f1_micro\tstd_f1_micro\tmean_mcc\tstd_mcc\tmin_mcc\tmax_mcc\n","#df_dict_A2.columns = [str(col) + '_a2' for col in ['mean_accuracy', 'std_accuracy', 'min_accuracy', 'max_accuracy', 'mean_f1_macro', 'min_f1_macro', 'max_f1_macro', 'std_f1_macro', 'mean_f1_micro', 'min_f1_micro', 'max_f1_micro', 'std_f1_micro', 'mean_mcc', 'std_mcc', 'min_mcc', 'max_mcc']]\n","\n","#df_full_dict = df_dict_A2.join(df_dict_A3.set_index('name'), on='name', rsuffix='_a3')\n","#df_full_dict = df_full_dict.join(df_dict_A4.set_index('name'), on='name', rsuffix='_a4')\n","#df_full_dict = df_full_dict.join(df_dict_A12.set_index('name'), on='name', rsuffix='_a12')\n","#df_full_dict = df_full_dict.join(df_dict_A21.set_index('name'), on='name', rsuffix='_a21')\n","\n","df_full_dict = df_dict_A2.join(df_dict_A3, rsuffix='_a3')\n","df_full_dict = df_full_dict.join(df_dict_A4, rsuffix='_a4')\n","df_full_dict = df_full_dict.join(df_dict_A12, rsuffix='_a12')\n","df_full_dict = df_full_dict.join(df_dict_A21, rsuffix='_a21')\n","\n","# calculate the mean mean accuracy \n","df_full_dict['mean_mean_accuracy'] = (df_full_dict['mean_accuracy'] + df_full_dict['mean_accuracy_a3'] + df_full_dict['mean_accuracy_a4'] + df_full_dict['mean_accuracy_a12'] + df_full_dict['mean_accuracy_a21']) / 5\n","\n","\n","df_full_dict = df_full_dict.loc[:, ~df_full_dict.columns.duplicated()].copy()\n","df_full_dict = df_full_dict.drop_duplicates()\n","df_full_dict[\"loss_criterion\"] = \"if dataset == 'a12': losses_per_epoch[dataset] += loss * 1 else: losses_per_epoch[dataset] += loss for dataset in helper.dataset_list: losses_per_epoch[dataset] /= len(X_train[dataset]) loss = sum(losses_per_epoch.values())\"\n","\n","\n","df_full_dict.to_csv(\"outputs/Feature_based/mtl_fnn/Feature_based_dropout__full_split_metrics_system.csv\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["df_dict_full_A2.to_csv(\"outputs/Feature_based/mtl_fnn/A2.csv\")\n","df_dict_full_A3.to_csv(\"outputs/Feature_based/mtl_fnn/A3.csv\")\n","df_dict_full_A4.to_csv(\"outputs/Feature_based/mtl_fnn/A4.csv\")\n","df_dict_full_A12.to_csv(\"outputs/Feature_based/mtl_fnn/A12.csv\")\n","df_dict_full_A21.to_csv(\"outputs/Feature_based/mtl_fnn/A21.csv\")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The best config is {'activation': 'relu', 'learning_rate': 0.00010438540045924504, 'batch_size': 64, 'shared_hidden_layers': (), 'a2_output_hidden_layers': (30, 40), 'a3_output_hidden_layers': (30, 10), 'a4_output_hidden_layers': (50, 10), 'a12_output_hidden_layers': (50, 50), 'a21_output_hidden_layers': (20, 40), 'epochs': 60, 'dropout_rate': 0.22976860346279732} with a mean accuracy for a12 of 0.2613554511253029\n","a2\n","a3\n","a4\n","a12\n","a21\n","     mean_accuracy_a21  std_accuracy_a21  mean_f1_macro_a21  std_f1_macro_a21  \\\n","198           0.595094          0.077525           0.460334          0.076062   \n","\n","     mean_f1_micro_a21  std_f1_micro_a21  mean_mcc_a21  std_mcc_a21  \n","198           0.595094          0.077525      0.112809     0.073754  \n"]}],"source":["# print the configs and results for the hyperparemters wiht the highest mean accuracy\n","# read df_full_dict and print columns with configs in best_params_list_getting\n","df_full_dict = pd.read_csv(\"outputs/Feature_based/mtl_fnn/Feature_based_dropout__full_split_metrics_system.csv\")\n","\n","config_acc_dict = {}\n","#for good_param in best_params_list_getting:\n","#    # get the row witht the highest mean mean accuracy\n","#    mean_accuracy_a12 = df_full_dict.loc[df_full_dict['config'] == str(good_param)]['mean_accuracy_a12']\n","#    config_acc_dict[str(good_param)] = mean_accuracy_a12\n","#    print(f\"Mean accuracy for a12 config {good_param} is {mean_accuracy_a12}\")\n","\n","# get the best config\n","# TODO get config where a12 has the highest mean accuracy\n","\n","for i in range(0, len(df_full_dict)):\n","    mean_accuracy_a12 = df_full_dict.loc[i]['mean_accuracy_a12']\n","    config_acc_dict[df_full_dict.loc[i]['config']] = mean_accuracy_a12\n","\n","best_config = max(config_acc_dict, key=config_acc_dict.get)\n","print(f\"The best config is {best_config} with a mean accuracy for a12 of {config_acc_dict[best_config]}\")\n","\n","#print aggregate results for the best config\n","print(\"a2\")\n","metrics = ['mean_accuracy', 'std_accuracy', 'mean_f1_macro', 'std_f1_macro', 'mean_f1_micro', 'std_f1_micro', 'mean_mcc', 'std_mcc']\n","print(\"a3\")\n","metrics = ['mean_accuracy_a3', 'std_accuracy_a3', 'mean_f1_macro_a3', 'std_f1_macro_a3', 'mean_f1_micro_a3', 'std_f1_micro_a3', 'mean_mcc_a3', 'std_mcc_a3']\n","print(\"a4\")\n","metrics = [ 'mean_accuracy_a4', 'std_accuracy_a4', 'mean_f1_macro_a4', 'std_f1_macro_a4', 'mean_f1_micro_a4', 'std_f1_micro_a4', 'mean_mcc_a4', 'std_mcc_a4']\n","print(\"a12\")\n","metrics = ['mean_accuracy_a12', 'std_accuracy_a12', 'mean_f1_macro_a12', 'std_f1_macro_a12', 'mean_f1_micro_a12', 'std_f1_micro_a12', 'mean_mcc_a12', 'std_mcc_a12']\n","print(\"a21\")\n","metrics = ['mean_accuracy_a21', 'std_accuracy_a21', 'mean_f1_macro_a21', 'std_f1_macro_a21', 'mean_f1_micro_a21', 'std_f1_micro_a21', 'mean_mcc_a21', 'std_mcc_a21']\n","print(df_full_dict[metrics].loc[df_full_dict['config'] == best_config])\n","\n","\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5354302,"sourceId":8905505,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
