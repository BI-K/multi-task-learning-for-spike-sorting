{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:34:55,778\tINFO worker.py:1772 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, ReLU, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.air import session\n",
    "from ray.tune.integration.keras import TuneReportCallback\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "\n",
    "import helper\n",
    "\n",
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Check if MPS (Apple Silicon) or CUDA (Nvidia) GPU is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Data Files Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_folder(folder_path):\n",
    "    for item in os.listdir(folder_path):\n",
    "        item_path = os.path.join(folder_path, item)\n",
    "        if item == '.gitignore':\n",
    "            continue\n",
    "        if os.path.isfile(item_path):\n",
    "            os.remove(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "\n",
    "clear_folder(\"ray_results\")\n",
    "clear_folder(\"outputs\")\n",
    "clear_folder(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Based MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO activation for now only relu\n",
    "class FeatureBasedMTLModel(nn.Module):\n",
    "    def __init__(self, hidden_layers_shared=[50,30], hidden_layers_outputs=[[10],[10],[10],[10],[10]], activation='relu', dropout_rate=0.3):\n",
    "        super(FeatureBasedMTLModel, self).__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        # shared LSTM layers\n",
    "        self.lstm_layers = nn.ModuleList()\n",
    "        self.lstm_layers.append(nn.LSTM(input_size=1, hidden_size=32, batch_first=True))\n",
    "        self.lstm_layers.append(nn.LSTM(input_size=32, hidden_size=64, batch_first=True))\n",
    "\n",
    "        input_dim = 64  # Adjusted input dimension after LSTM layers\n",
    "\n",
    "        self.shared_layers = nn.ModuleList()\n",
    "        for hidden_layer in hidden_layers_shared:\n",
    "            self.shared_layers.append(nn.Linear(input_dim, hidden_layer))\n",
    "            self.shared_layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_layer\n",
    "\n",
    "        # output layers\n",
    "        self.output_a2 = self.create_output_layers(hidden_layers_outputs[0], input_dim, 2)\n",
    "        self.output_a3 = self.create_output_layers(hidden_layers_outputs[1], input_dim, 2)\n",
    "        self.output_a4 = self.create_output_layers(hidden_layers_outputs[2], input_dim, 3)\n",
    "        self.output_a12 = self.create_output_layers(hidden_layers_outputs[3], input_dim, 6)\n",
    "        self.output_a21 = self.create_output_layers(hidden_layers_outputs[4], input_dim, 2)\n",
    "\n",
    "    def create_output_layers(self, hidden_layers, input_dim, output_dim):\n",
    "        layers = nn.ModuleList()\n",
    "        for hidden_layer in hidden_layers:\n",
    "            layers.append(nn.Linear(input_dim, hidden_layer))\n",
    "            input_dim = hidden_layer\n",
    "        layers.append(nn.Linear(input_dim, output_dim))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x: torch.Tensor, task_id: str):\n",
    "        # Add input size dimension\n",
    "        x = x.unsqueeze(-1)  # Shape: (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # LSTM layers\n",
    "        for lstm in self.lstm_layers:\n",
    "            x, (hn, cn) = lstm(x)\n",
    "\n",
    "        x = x[:, -1, :]  # Take the output of the last LSTM cell\n",
    "\n",
    "        # shared layers\n",
    "        for layer in self.shared_layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                x = layer(x)\n",
    "                x = self.apply_activation(x)\n",
    "            elif isinstance(layer, nn.Dropout):\n",
    "                x = layer(x)\n",
    "        \n",
    "        # output layers\n",
    "        if task_id == 'a2':\n",
    "            return self.forward_output_layers(x, self.output_a2)\n",
    "        elif task_id == 'a3':\n",
    "            return self.forward_output_layers(x, self.output_a3)\n",
    "        elif task_id == 'a4':\n",
    "            return self.forward_output_layers(x, self.output_a4)\n",
    "        elif task_id == 'a12':\n",
    "            return self.forward_output_layers(x, self.output_a12)\n",
    "        elif task_id == 'a21':\n",
    "            return self.forward_output_layers(x, self.output_a21)\n",
    "        else:\n",
    "            raise ValueError(f'Invalid task_id: {task_id}')\n",
    "        \n",
    "\n",
    "    def forward_output_layers(self, x, layers):\n",
    "        for layer in layers[:-1]:\n",
    "            x = layer(x)\n",
    "            x = self.apply_activation(x)\n",
    "            \n",
    "        x = layers[-1](x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def apply_activation(self, x):\n",
    "        if self.activation == 'relu':\n",
    "            return F.relu(x)\n",
    "        elif self.activation == 'tanh':\n",
    "            return F.tanh(x)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return F.sigmoid(x)\n",
    "        else:\n",
    "            raise ValueError(f'Invalid activation: {self.activation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_batches(X_train, y_train, batch_size):\n",
    "    X_train_batches = {'a2': {}, 'a3': {}, 'a4': {}, 'a12': {}, 'a21': {}}\n",
    "    y_train_batches = {'a2': {}, 'a3': {}, 'a4': {}, 'a12': {}, 'a21': {}}\n",
    "\n",
    "    for dataset in helper.dataset_list:\n",
    "\n",
    "        for i in range(0, floor(len(X_train[dataset])/batch_size)):\n",
    "                X_train_batches[dataset][str(i)] =  X_train[dataset].iloc[i* batch_size:i*batch_size+batch_size]\n",
    "                y_train_batches[dataset][str(i)] =  y_train[dataset].iloc[i* batch_size:i* batch_size+batch_size]\n",
    "\n",
    "    return X_train_batches, y_train_batches\n",
    "\n",
    "# batchsize in this case refers to the size of batch per dataset\n",
    "def train(model, X_train, y_train, num_epochs, batch_size, learning_rate):\n",
    "\n",
    "        model = model.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "        max_number_of_batches = max(len(X_train[dataset]) // batch_size for dataset in helper.dataset_list)\n",
    "\n",
    "        X_train, y_train = create_batches(X_train, y_train, batch_size)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                losses_per_epoch = {'a2': 0, 'a3': 0, 'a4': 0, 'a12': 0, 'a21': 0}\n",
    "\n",
    "                for batch_number in range(0, max_number_of_batches):\n",
    "\n",
    "                        for dataset in helper.dataset_list:\n",
    "\n",
    "                                if len(X_train[dataset]) > batch_number:\n",
    "\n",
    "                                        X_train_tensor = torch.tensor(X_train[dataset][str(batch_number)].values, dtype=torch.float32, device=device)\n",
    "                                        y_train_tensor= torch.tensor(y_train[dataset][str(batch_number)].values, dtype=torch.float32, device=device)\n",
    "                                        outputs = model(X_train_tensor, task_id = dataset)\n",
    "                                        loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "                                        losses_per_epoch[dataset] += loss\n",
    "\n",
    "                for dataset in helper.dataset_list:\n",
    "                        losses_per_epoch[dataset] /= len(X_train[dataset])\n",
    "\n",
    "                # for now sum of average loss per dataset\n",
    "                loss = sum(losses_per_epoch.values())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def mcc(fn, fp, tn, tp):\n",
    "    return (tp * tn - fp * fn) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "def evaluate(model, X_test, y_test, device='cpu'):\n",
    "\n",
    "    eval_dict = {'a2': {}, 'a3': {}, 'a4': {}, 'a12': {}, 'a21': {}}\n",
    "    num_classes = {'a2': 2, 'a3': 2, 'a4': 3, 'a12': 6, 'a21': 2}\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for dataset in helper.dataset_list:\n",
    "        X_test_tensor = torch.tensor(X_test[dataset].values, dtype=torch.float32, device=device)\n",
    "        # y_test_tensor = torch.tensor(y_test[dataset].values, dtype=torch.float32)\n",
    "        y_pred_tensor = model(X_test_tensor, task_id=dataset)\n",
    "        y_pred = y_pred_tensor.detach().cpu().numpy()  # Move tensor to CPU before converting to NumPy\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # print(y_test[dataset])\n",
    "        y_test_np = y_test[dataset].to_numpy()\n",
    "        # print(y_test_np)\n",
    "        y_test_np = np.argmax(y_test_np, axis=1)\n",
    "        # print(y_test_np)\n",
    "\n",
    "        # Calculate classification metrics using one-hot encoded targets\n",
    "        eval_dict[dataset]['accuracy'] = accuracy_score(y_test_np, y_pred)\n",
    "        eval_dict[dataset]['micro_f1'] = f1_score(y_test_np, y_pred, average='micro')\n",
    "        eval_dict[dataset]['macro_f1'] = f1_score(y_test_np, y_pred, average='macro')\n",
    "        # gets 0 quite often...???\n",
    "        eval_dict[dataset]['mcc'] = matthews_corrcoef(y_test_np, y_pred)\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_dataset_one_split(split_index, config):\n",
    "\n",
    "    X_train, X_test, y_train, y_test =  helper.get_joined_train_test_folds(split_index)\n",
    "    # print(y_test)\n",
    "\n",
    "    model = FeatureBasedMTLModel(activation=config['activation'], hidden_layers_shared=config['shared_hidden_layers'], hidden_layers_outputs=[\n",
    "        config['a2_output_hidden_layers'], config['a3_output_hidden_layers'], config['a4_output_hidden_layers'], config['a12_output_hidden_layers'], config['a21_output_hidden_layers'],\n",
    "        config['dropout_rate']\n",
    "    ])\n",
    "\n",
    "    # Train the model and collect performance data\n",
    "    model = train(model, X_train, y_train, num_epochs=config['epochs'], batch_size=config['batch_size'], learning_rate=config['learning_rate'],)\n",
    "    # Evaluate the model and collect performance data\n",
    "    eval_dict = evaluate(model, X_test, y_test)\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_spike_1_split = {\n",
    "    'a2': pd.DataFrame(),\n",
    "    'a3': pd.DataFrame(),\n",
    "    'a4': pd.DataFrame(),\n",
    "    'a12': pd.DataFrame(),\n",
    "    'a21': pd.DataFrame()\n",
    "}\n",
    "\n",
    "df_data_spike_full_split = pd.DataFrame()\n",
    "\n",
    "data_spike_exec_1_split_dict = dict()\n",
    "data_spike_exec_full_split_dict = {\n",
    "    'a2': {},\n",
    "    'a3': {},\n",
    "    'a4': {},\n",
    "    'a12': {},\n",
    "    'a21': {}\n",
    "}\n",
    "\n",
    "\n",
    "best_params_list_getting = []\n",
    "\n",
    "def custom_trial_dirname(trial):\n",
    "    return f\"trial_{trial.trial_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(config):\n",
    "    \n",
    "    global data_spike_exec_1_split_dict\n",
    "    global data_spike_exec_full_split_dict\n",
    "    global df_data_spike_1_split\n",
    "    global results_dir\n",
    "\n",
    "    overall_result = {\n",
    "    \"a2\": {\n",
    "        \"accuracy_scores\": [],\n",
    "        \"f1_macro_scores\": [],\n",
    "        \"f1_micro_scores\": [],\n",
    "        \"mcc_scores\": []\n",
    "    },\n",
    "    \"a3\": {\n",
    "        \"accuracy_scores\": [],\n",
    "        \"f1_macro_scores\": [],\n",
    "        \"f1_micro_scores\": [],\n",
    "        \"mcc_scores\": []\n",
    "    },\n",
    "    \"a4\": { \n",
    "        \"accuracy_scores\": [],\n",
    "        \"f1_macro_scores\": [],\n",
    "        \"f1_micro_scores\": [],\n",
    "        \"mcc_scores\": []\n",
    "    },\n",
    "    \"a12\": {\n",
    "        \"accuracy_scores\": [],\n",
    "        \"f1_macro_scores\": [],\n",
    "        \"f1_micro_scores\": [],\n",
    "        \"mcc_scores\": []\n",
    "    },\n",
    "    \"a21\": {\n",
    "        \"accuracy_scores\": [],\n",
    "        \"f1_macro_scores\": [],\n",
    "        \"f1_micro_scores\": [],\n",
    "        \"mcc_scores\": []\n",
    "    }\n",
    "    }\n",
    "\n",
    "    accuracy_scores = []\n",
    "    f1_macro_scores = []\n",
    "    f1_micro_scores = []\n",
    "    mcc_scores = []\n",
    "\n",
    "    data_spike_exec_1_split_dict = {}\n",
    "    for dataset in overall_result.keys():\n",
    "        data_spike_exec_1_split_dict[dataset] = pd.DataFrame()\n",
    "\n",
    "    session_id_for_df = session.get_trial_id()\n",
    "    print(type(session_id_for_df))\n",
    "    \n",
    "    # save individual results for each dataset\n",
    "    for i in range(5):\n",
    "        eval_dict = evaluate_model_on_dataset_one_split(i, config)\n",
    "        # fill all nan values in eval_dict with 0\n",
    "        for dataset in eval_dict.keys():\n",
    "            for key in eval_dict[dataset].keys():\n",
    "                if np.isnan(eval_dict[dataset][key]):\n",
    "                    eval_dict[dataset][key] = 0\n",
    "        \n",
    "        for dataset in overall_result.keys():\n",
    "\n",
    "            overall_result[dataset]['accuracy_scores'].append(eval_dict[dataset]['accuracy'])\n",
    "            overall_result[dataset]['f1_macro_scores'].append(eval_dict[dataset]['macro_f1'])\n",
    "            overall_result[dataset]['f1_micro_scores'].append(eval_dict[dataset]['micro_f1'])\n",
    "            overall_result[dataset]['mcc_scores'].append(eval_dict[dataset]['mcc'])\n",
    "\n",
    "            accuracy_scores.append(eval_dict[dataset]['accuracy'])\n",
    "            f1_macro_scores.append(eval_dict[dataset]['macro_f1'])\n",
    "            f1_micro_scores.append(eval_dict[dataset]['micro_f1'])\n",
    "            mcc_scores.append(eval_dict[dataset]['mcc'])\n",
    "            \n",
    "            new_entry= pd.DataFrame({\n",
    "            #data_spike_exec_1_split_dict[dataset][dataset + \"_\" + str(i+1) + \"_\" + session_id_for_df] = {\n",
    "                \"name\": [dataset + \"_\" + str(i+1) + \"_\" + session_id_for_df],\n",
    "                \"accuracy\": [eval_dict[dataset]['accuracy']],\n",
    "                \"macro f1\": [eval_dict[dataset]['macro_f1']],\n",
    "                \"micro_f1\": [eval_dict[dataset]['micro_f1']],\n",
    "                \"mcc\": [eval_dict[dataset]['mcc']],\n",
    "                \"config\": [str(config)]\n",
    "            })\n",
    "\n",
    "            if i == 0:\n",
    "                df_data_spike_1_split[dataset] = new_entry\n",
    "            else:\n",
    "                df_data_spike_1_split[dataset]= pd.concat([df_data_spike_1_split[dataset], new_entry], ignore_index=True, axis=0)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    for dataset in overall_result.keys():\n",
    "\n",
    "        #data_spike_exec_full_split_dict[dataset][dataset + \"_\" + session_id_for_df] = {\n",
    "        new_data_spike_exec_full_split_dict = pd.DataFrame({\n",
    "                \"name\" : [dataset + \"_\" + session_id_for_df],\n",
    "                \"min_accuracy\": [min(overall_result[dataset]['accuracy_scores'])],\n",
    "                \"max_accuracy\": [max(overall_result[dataset]['accuracy_scores'])],\n",
    "                \"min_f1_macro\": [min(overall_result[dataset]['f1_macro_scores'])],\n",
    "                \"max_f1_macro\": [max(overall_result[dataset]['f1_macro_scores'])],\n",
    "                \"min_mcc\": [min(overall_result[dataset]['mcc_scores'])],\n",
    "                \"max_mcc\": [max(overall_result[dataset]['mcc_scores'])],\n",
    "                \"mean_accuracy\": [np.mean(overall_result[dataset]['accuracy_scores'])],\n",
    "                \"mean_f1_macro\": [np.mean(overall_result[dataset]['f1_macro_scores'])],\n",
    "                \"mean_f1_micro\": [np.mean(overall_result[dataset]['f1_micro_scores'])],\n",
    "                \"mean_mcc\": [np.mean(overall_result[dataset]['mcc_scores'])],\n",
    "                \"std_accuracy\": [np.std(overall_result[dataset]['accuracy_scores'])],\n",
    "                \"std_f1_macro\": [np.std(overall_result[dataset]['f1_macro_scores'])],\n",
    "                \"std_f1_micro\": [np.std(overall_result[dataset]['f1_micro_scores'])],\n",
    "                \"std_mcc\": [np.std(overall_result[dataset]['mcc_scores'])],\n",
    "                \"config\": [str(config)]\n",
    "        })\n",
    "\n",
    "        full_split_path = os.path.join(helper.results_dir, f'Feature_based_output_full_{dataset}.pkl')\n",
    "        if os.path.exists(full_split_path):\n",
    "            df_existing_full = pd.read_pickle(full_split_path)\n",
    "            df_data_spike_full_split = pd.concat([df_existing_full, new_data_spike_exec_full_split_dict], ignore_index=True, axis=0)\n",
    "        else:\n",
    "            print(f\"No existing full split data found at {full_split_path}, creating new file.\")\n",
    "            df_data_spike_full_split = new_data_spike_exec_full_split_dict\n",
    "        \n",
    "        # Save the updated full split data to file\n",
    "        df_data_spike_full_split.to_pickle(full_split_path)\n",
    "\n",
    "\n",
    "        # Save the 1 split data using the full path\n",
    "        split_path = os.path.join(helper.results_dir, f'Feature_based_output_{dataset}.pkl')\n",
    "        if os.path.exists(split_path):\n",
    "            df_existing_1_spike = pd.read_pickle(split_path)\n",
    "            df_data_spike_1_split[dataset] = pd.concat([df_data_spike_1_split[dataset], df_existing_1_spike], ignore_index=True, axis=0)\n",
    "        else:\n",
    "            print(f\"No existing 1 split data found at {split_path}, creating new file\")\n",
    "\n",
    "        # Save the updated 1 split data to file\n",
    "        df_data_spike_1_split[dataset].to_pickle(split_path)\n",
    "\n",
    "    if np.min(accuracy_scores) == 0:\n",
    "        print(f\"Zero accuracy detected in config: {config}\")\n",
    "        print(f\"Accuracy scores: {accuracy_scores}\")\n",
    "\n",
    "    session.report({\n",
    "        \"min_mean_accuracy\": np.min(accuracy_scores),\n",
    "        \"max_mean_accuracy\": np.max(accuracy_scores),\n",
    "        \"mean_mean_accuracy\": np.mean(accuracy_scores),\n",
    "        \"mean_mean_f1_macro\": np.mean(f1_macro_scores),\n",
    "        \"mean_mean_f1_micro\": np.mean(f1_micro_scores),\n",
    "        \"mean_mean_mcc\": np.mean(mcc_scores)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hidden_layers_config(min_layers=1, max_layers=5, min_nodes=10, max_nodes=50, step=10):\n",
    "    possible_layers = []\n",
    "\n",
    "    for num_layers in range(min_layers, max_layers + 1):\n",
    "\n",
    "        shared_layers = list(itertools.product(range(min_nodes, max_nodes + 1, step), repeat=num_layers))\n",
    "\n",
    "        max_output_layers = max_layers - num_layers\n",
    "        \n",
    "        output_layers = []\n",
    "        for num_output_layers in range(0, max_output_layers + 1):\n",
    "\n",
    "            output_layers = list(itertools.product(range(min_nodes, max_nodes + 1, step), repeat=num_output_layers))\n",
    "\n",
    "        possible_layers.append({'shared': shared_layers, 'output': {'a2': output_layers, 'a3': output_layers, 'a4': output_layers, 'a12': output_layers, 'a21': output_layers}})\n",
    "\n",
    "    return possible_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_fold_cross_validation(num_layers):\n",
    "\n",
    "    num_layers = num_layers - 1\n",
    "\n",
    "    global best_params_list_getting\n",
    "\n",
    "    hidden_layers_options = generate_hidden_layers_config()\n",
    "\n",
    "    config = {\n",
    "        \"activation\": tune.choice([\"relu\", \"tanh\", \"sigmoid\"]),\n",
    "        \"learning_rate\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"batch_size\": tune.choice([32, 64, 128]),\n",
    "        \"shared_hidden_layers\": tune.choice(hidden_layers_options[num_layers]['shared']),\n",
    "        \"a2_output_hidden_layers\": tune.choice(hidden_layers_options[num_layers]['output']['a2']),\n",
    "        \"a3_output_hidden_layers\": tune.choice(hidden_layers_options[num_layers]['output']['a3']),\n",
    "        \"a4_output_hidden_layers\": tune.choice(hidden_layers_options[num_layers]['output']['a4']),\n",
    "        \"a12_output_hidden_layers\": tune.choice(hidden_layers_options[num_layers]['output']['a12']),\n",
    "        \"a21_output_hidden_layers\": tune.choice(hidden_layers_options[num_layers]['output']['a21']),\n",
    "        \"epochs\": tune.choice([10, 20, 30, 40, 50]),\n",
    "        \"dropout_rate\": tune.uniform(0.2, 0.5)\n",
    "    }\n",
    "    \n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"mean_mean_accuracy\",\n",
    "        mode=\"max\",\n",
    "        max_t=10,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    \n",
    "    search_alg = OptunaSearch(metric=\"mean_mean_accuracy\", mode=\"max\")\n",
    "    \n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(train_and_evaluate),\n",
    "        resources_per_trial={\"cpu\": 10, \"gpu\": 0, \"accelerator_type:RTX\": 0},\n",
    "        config=config,\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search_alg,\n",
    "        num_samples=10,\n",
    "        verbose=1,\n",
    "        storage_path=helper.ray_results_dir,\n",
    "        trial_dirname_creator=custom_trial_dirname\n",
    "    )\n",
    "\n",
    "    best_config_data_ray_tune = analysis.get_best_config(metric=\"mean_mean_accuracy\", mode=\"max\")\n",
    "    print(\"Best hyperparameters found were: \", best_config_data_ray_tune)\n",
    "    best_params_list_getting.append(best_config_data_ray_tune)\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 10:51:10</td></tr>\n",
       "<tr><td>Running for: </td><td>00:16:10.00        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.3/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.4586460758483839<br>Logical resource usage: 10.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>a12_output_hidden_la\n",
       "yers   </th><th>a21_output_hidden_la\n",
       "yers   </th><th>a2_output_hidden_lay\n",
       "ers   </th><th>a3_output_hidden_lay\n",
       "ers   </th><th>a4_output_hidden_lay\n",
       "ers   </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  min_mean_accuracy</th><th style=\"text-align: right;\">  max_mean_accuracy</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_83fc5c85</td><td>TERMINATED</td><td>127.0.0.1:33275</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.274582</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000714505</td><td>(10, 20, 50, 20, 30)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         82.4031</td><td style=\"text-align: right;\">           0.158031</td><td style=\"text-align: right;\">           0.84058 </td><td style=\"text-align: right;\">            0.478015</td></tr>\n",
       "<tr><td>train_and_evaluate_d970aac7</td><td>TERMINATED</td><td>127.0.0.1:33452</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.20637 </td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00696708 </td><td>(40, 50, 30, 20, 50)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         35.0504</td><td style=\"text-align: right;\">           0.139535</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.451576</td></tr>\n",
       "<tr><td>train_and_evaluate_e28cee4d</td><td>TERMINATED</td><td>127.0.0.1:33511</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>sigmoid     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.219916</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00127089 </td><td>(50, 40, 50, 10, 20)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         46.1149</td><td style=\"text-align: right;\">           0.136951</td><td style=\"text-align: right;\">           0.714286</td><td style=\"text-align: right;\">            0.409324</td></tr>\n",
       "<tr><td>train_and_evaluate_f525426e</td><td>TERMINATED</td><td>127.0.0.1:33608</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.221561</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000887578</td><td>(10, 30, 50, 10, 10)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         51.5183</td><td style=\"text-align: right;\">           0.134715</td><td style=\"text-align: right;\">           0.757009</td><td style=\"text-align: right;\">            0.453318</td></tr>\n",
       "<tr><td>train_and_evaluate_6433b0fd</td><td>TERMINATED</td><td>127.0.0.1:33763</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.237757</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000341862</td><td>(50, 30, 50, 20, 40)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         67.7777</td><td style=\"text-align: right;\">           0.15285 </td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.408534</td></tr>\n",
       "<tr><td>train_and_evaluate_f80dd3d7</td><td>TERMINATED</td><td>127.0.0.1:33903</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.256982</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000545275</td><td>(50, 50, 30, 50, 20)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        101.52  </td><td style=\"text-align: right;\">           0.132124</td><td style=\"text-align: right;\">           0.898551</td><td style=\"text-align: right;\">            0.531708</td></tr>\n",
       "<tr><td>train_and_evaluate_7ceb7da0</td><td>TERMINATED</td><td>127.0.0.1:34087</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.309143</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000201192</td><td>(50, 10, 40, 50, 20)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        168.673 </td><td style=\"text-align: right;\">           0.160207</td><td style=\"text-align: right;\">           0.685714</td><td style=\"text-align: right;\">            0.419845</td></tr>\n",
       "<tr><td>train_and_evaluate_7bcfdeab</td><td>TERMINATED</td><td>127.0.0.1:34369</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.427156</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000901254</td><td>(10, 10, 50, 30, 20)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        177.505 </td><td style=\"text-align: right;\">           0.207254</td><td style=\"text-align: right;\">           0.953271</td><td style=\"text-align: right;\">            0.610798</td></tr>\n",
       "<tr><td>train_and_evaluate_22196603</td><td>TERMINATED</td><td>127.0.0.1:34781</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.222118</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00852018 </td><td>(40, 20, 20, 10, 50)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        104.631 </td><td style=\"text-align: right;\">           0.15544 </td><td style=\"text-align: right;\">           0.794393</td><td style=\"text-align: right;\">            0.487839</td></tr>\n",
       "<tr><td>train_and_evaluate_047c0b13</td><td>TERMINATED</td><td>127.0.0.1:34976</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.218119</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000472191</td><td>(30, 10, 10, 30, 10)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        104.143 </td><td style=\"text-align: right;\">           0.144703</td><td style=\"text-align: right;\">           0.757009</td><td style=\"text-align: right;\">            0.463974</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:36:25,275\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 20, 50, 20, 30), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing full split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_full_a2.pkl, creating new file.\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing 1 split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_a2.pkl, creating new file\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing full split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_full_a3.pkl, creating new file.\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing 1 split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_a3.pkl, creating new file\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing full split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_full_a4.pkl, creating new file.\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing 1 split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_a4.pkl, creating new file\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing full split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_full_a12.pkl, creating new file.\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing 1 split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_a12.pkl, creating new file\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing full split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_full_a21.pkl, creating new file.\n",
      "\u001b[36m(train_and_evaluate pid=33275)\u001b[0m No existing 1 split data found at /Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/results/Feature_based_output_a21.pkl, creating new file\n",
      "\u001b[36m(train_and_evaluate pid=33452)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:37:03,635\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 50, 30, 20, 50), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=33511)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:37:52,434\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 40, 50, 10, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=33608)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:38:47,408\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 30, 50, 10, 10), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=33763)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:39:58,642\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 30, 50, 20, 40), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=33903)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:41:43,291\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 50, 30, 50, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=34087)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:44:34,528\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 10, 40, 50, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=34369)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:47:35,111\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 10, 50, 30, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=34781)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:49:23,076\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 20, 20, 10, 50), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=34976)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:51:10,773\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 10, 10, 30, 10), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n",
      "2024-08-08 10:51:10,780\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-08-08_10-35-00' in 0.0064s.\n",
      "2024-08-08 10:51:10,784\tINFO tune.py:1041 -- Total run time: 970.08 seconds (970.00 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'activation': 'tanh', 'learning_rate': 0.0009012544512547965, 'batch_size': 32, 'shared_hidden_layers': (10, 10, 50, 30, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': (), 'epochs': 50, 'dropout_rate': 0.4271563988934437}\n"
     ]
    }
   ],
   "source": [
    "analysis = five_fold_cross_validation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 11:03:14</td></tr>\n",
       "<tr><td>Running for: </td><td>00:12:03.71        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.4/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.43346882459305436<br>Logical resource usage: 10.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>a12_output_hidden_la\n",
       "yers      </th><th>a21_output_hidden_la\n",
       "yers      </th><th>a2_output_hidden_lay\n",
       "ers      </th><th>a3_output_hidden_lay\n",
       "ers      </th><th>a4_output_hidden_lay\n",
       "ers      </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  min_mean_accuracy</th><th style=\"text-align: right;\">  max_mean_accuracy</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_dc2e7105</td><td>TERMINATED</td><td>127.0.0.1:35147</td><td>(50,)</td><td>(30,)</td><td>(20,)</td><td>(10,)</td><td>(50,)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.409901</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000603447</td><td>(40, 10, 20, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         20.031 </td><td style=\"text-align: right;\">           0.155039</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.418228</td></tr>\n",
       "<tr><td>train_and_evaluate_940639a9</td><td>TERMINATED</td><td>127.0.0.1:35193</td><td>(50,)</td><td>(50,)</td><td>(20,)</td><td>(30,)</td><td>(20,)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.379612</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000151037</td><td>(10, 10, 40, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         71.1476</td><td style=\"text-align: right;\">           0.168394</td><td style=\"text-align: right;\">           0.782609</td><td style=\"text-align: right;\">            0.465438</td></tr>\n",
       "<tr><td>train_and_evaluate_0fce5b2c</td><td>TERMINATED</td><td>127.0.0.1:35333</td><td>(10,)</td><td>(10,)</td><td>(30,)</td><td>(30,)</td><td>(10,)</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.387741</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00385407 </td><td>(30, 30, 10, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         29.4522</td><td style=\"text-align: right;\">           0.147668</td><td style=\"text-align: right;\">           0.831776</td><td style=\"text-align: right;\">            0.526811</td></tr>\n",
       "<tr><td>train_and_evaluate_acadd123</td><td>TERMINATED</td><td>127.0.0.1:35431</td><td>(10,)</td><td>(30,)</td><td>(50,)</td><td>(30,)</td><td>(30,)</td><td>sigmoid     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.431458</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000306005</td><td>(10, 40, 50, 10)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         83.1737</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.417512</td></tr>\n",
       "<tr><td>train_and_evaluate_d2a4d633</td><td>TERMINATED</td><td>127.0.0.1:35566</td><td>(30,)</td><td>(50,)</td><td>(40,)</td><td>(40,)</td><td>(20,)</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.275133</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00545976 </td><td>(20, 10, 20, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         94.3697</td><td style=\"text-align: right;\">           0.111111</td><td style=\"text-align: right;\">           0.826087</td><td style=\"text-align: right;\">            0.486885</td></tr>\n",
       "<tr><td>train_and_evaluate_a015c25a</td><td>TERMINATED</td><td>127.0.0.1:35712</td><td>(40,)</td><td>(40,)</td><td>(20,)</td><td>(30,)</td><td>(10,)</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.35835 </td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000339057</td><td>(30, 40, 30, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        175.204 </td><td style=\"text-align: right;\">           0.147668</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.414928</td></tr>\n",
       "<tr><td>train_and_evaluate_74965e27</td><td>TERMINATED</td><td>127.0.0.1:36124</td><td>(20,)</td><td>(40,)</td><td>(10,)</td><td>(20,)</td><td>(10,)</td><td>sigmoid     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.472759</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00145929 </td><td>(10, 50, 20, 50)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.6111</td><td style=\"text-align: right;\">           0.158031</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.407319</td></tr>\n",
       "<tr><td>train_and_evaluate_58c79dee</td><td>TERMINATED</td><td>127.0.0.1:36157</td><td>(30,)</td><td>(50,)</td><td>(30,)</td><td>(20,)</td><td>(10,)</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.254338</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.00044666 </td><td>(30, 30, 20, 40)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         66.2354</td><td style=\"text-align: right;\">           0.157623</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.41491 </td></tr>\n",
       "<tr><td>train_and_evaluate_d356abd5</td><td>TERMINATED</td><td>127.0.0.1:36299</td><td>(40,)</td><td>(50,)</td><td>(20,)</td><td>(30,)</td><td>(50,)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.216479</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00426113 </td><td>(20, 20, 20, 30)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         98.5289</td><td style=\"text-align: right;\">           0.158031</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.44871 </td></tr>\n",
       "<tr><td>train_and_evaluate_76f2e4d9</td><td>TERMINATED</td><td>127.0.0.1:36461</td><td>(20,)</td><td>(20,)</td><td>(40,)</td><td>(30,)</td><td>(20,)</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.338393</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00113719 </td><td>(50, 40, 20, 20)      </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.1854</td><td style=\"text-align: right;\">           0.183938</td><td style=\"text-align: right;\">           0.915888</td><td style=\"text-align: right;\">            0.612272</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=35147)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:51:33,662\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 10, 20, 10), 'a2_output_hidden_layers': (20,), 'a3_output_hidden_layers': (10,), 'a4_output_hidden_layers': (50,), 'a12_output_hidden_layers': (50,), 'a21_output_hidden_layers': (30,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=35193)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:52:48,180\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 10, 40, 50), 'a2_output_hidden_layers': (20,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (20,), 'a12_output_hidden_layers': (50,), 'a21_output_hidden_layers': (50,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=35333)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:53:20,992\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 30, 10, 40), 'a2_output_hidden_layers': (30,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (10,), 'a12_output_hidden_layers': (10,), 'a21_output_hidden_layers': (10,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=35431)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:54:47,158\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 40, 50, 10), 'a2_output_hidden_layers': (50,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (30,), 'a12_output_hidden_layers': (10,), 'a21_output_hidden_layers': (30,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=35566)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:56:25,107\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 10, 20, 20), 'a2_output_hidden_layers': (40,), 'a3_output_hidden_layers': (40,), 'a4_output_hidden_layers': (20,), 'a12_output_hidden_layers': (30,), 'a21_output_hidden_layers': (50,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=35712)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:59:23,114\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 40, 30, 40), 'a2_output_hidden_layers': (20,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (10,), 'a12_output_hidden_layers': (40,), 'a21_output_hidden_layers': (40,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=36124)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 10:59:36,804\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 50, 20, 50), 'a2_output_hidden_layers': (10,), 'a3_output_hidden_layers': (20,), 'a4_output_hidden_layers': (10,), 'a12_output_hidden_layers': (20,), 'a21_output_hidden_layers': (40,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=36157)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:00:46,019\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 30, 20, 40), 'a2_output_hidden_layers': (30,), 'a3_output_hidden_layers': (20,), 'a4_output_hidden_layers': (10,), 'a12_output_hidden_layers': (30,), 'a21_output_hidden_layers': (50,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=36299)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:02:27,725\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 20, 20, 30), 'a2_output_hidden_layers': (20,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (50,), 'a12_output_hidden_layers': (40,), 'a21_output_hidden_layers': (50,)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=36461)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:03:14,548\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 40, 20, 20), 'a2_output_hidden_layers': (40,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (20,), 'a12_output_hidden_layers': (20,), 'a21_output_hidden_layers': (20,)}\n",
      "2024-08-08 11:03:14,557\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-08-08_10-51-10' in 0.0071s.\n",
      "2024-08-08 11:03:14,562\tINFO tune.py:1041 -- Total run time: 723.74 seconds (723.70 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'activation': 'tanh', 'learning_rate': 0.001137191002648876, 'batch_size': 128, 'shared_hidden_layers': (50, 40, 20, 20), 'a2_output_hidden_layers': (40,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (20,), 'a12_output_hidden_layers': (20,), 'a21_output_hidden_layers': (20,), 'epochs': 50, 'dropout_rate': 0.3383933955559252}\n"
     ]
    }
   ],
   "source": [
    "analysis = five_fold_cross_validation(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 11:18:53</td></tr>\n",
       "<tr><td>Running for: </td><td>00:15:38.65        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.3/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=5<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.5664499793000131<br>Logical resource usage: 10.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>a12_output_hidden_la\n",
       "yers         </th><th>a21_output_hidden_la\n",
       "yers         </th><th>a2_output_hidden_lay\n",
       "ers         </th><th>a3_output_hidden_lay\n",
       "ers         </th><th>a4_output_hidden_lay\n",
       "ers         </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  min_mean_accuracy</th><th style=\"text-align: right;\">  max_mean_accuracy</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_15cea493</td><td>TERMINATED</td><td>127.0.0.1:36532</td><td>(20, 20)</td><td>(10, 30)</td><td>(50, 50)</td><td>(10, 40)</td><td>(10, 50)</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.312447</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000155856</td><td>(20, 20, 50)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        156.244 </td><td style=\"text-align: right;\">           0.183938</td><td style=\"text-align: right;\">           0.925234</td><td style=\"text-align: right;\">            0.627484</td></tr>\n",
       "<tr><td>train_and_evaluate_160206b9</td><td>TERMINATED</td><td>127.0.0.1:36825</td><td>(50, 30)</td><td>(50, 30)</td><td>(10, 40)</td><td>(20, 30)</td><td>(50, 40)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.233343</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000131949</td><td>(40, 10, 30)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        132.657 </td><td style=\"text-align: right;\">           0.178756</td><td style=\"text-align: right;\">           0.794393</td><td style=\"text-align: right;\">            0.497354</td></tr>\n",
       "<tr><td>train_and_evaluate_09e6ece5</td><td>TERMINATED</td><td>127.0.0.1:37091</td><td>(20, 30)</td><td>(30, 20)</td><td>(40, 30)</td><td>(50, 50)</td><td>(40, 30)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.202786</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00609727 </td><td>(30, 40, 50)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         80.5621</td><td style=\"text-align: right;\">           0.160622</td><td style=\"text-align: right;\">           0.888889</td><td style=\"text-align: right;\">            0.556838</td></tr>\n",
       "<tr><td>train_and_evaluate_3f6c617a</td><td>TERMINATED</td><td>127.0.0.1:37229</td><td>(30, 20)</td><td>(30, 30)</td><td>(30, 10)</td><td>(10, 10)</td><td>(20, 30)</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.261051</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00148749 </td><td>(40, 10, 20)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         42.9994</td><td style=\"text-align: right;\">           0.150259</td><td style=\"text-align: right;\">           0.841121</td><td style=\"text-align: right;\">            0.504332</td></tr>\n",
       "<tr><td>train_and_evaluate_cf3ad807</td><td>TERMINATED</td><td>127.0.0.1:37323</td><td>(20, 20)</td><td>(30, 20)</td><td>(30, 10)</td><td>(30, 50)</td><td>(50, 50)</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.383481</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00383954 </td><td>(30, 10, 40)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        133.684 </td><td style=\"text-align: right;\">           0.168394</td><td style=\"text-align: right;\">           0.913043</td><td style=\"text-align: right;\">            0.604228</td></tr>\n",
       "<tr><td>train_and_evaluate_4bcbf08a</td><td>TERMINATED</td><td>127.0.0.1:37664</td><td>(40, 10)</td><td>(30, 50)</td><td>(30, 40)</td><td>(10, 30)</td><td>(50, 20)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.217877</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00564981 </td><td>(40, 30, 40)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         65.8023</td><td style=\"text-align: right;\">           0.168394</td><td style=\"text-align: right;\">           0.914286</td><td style=\"text-align: right;\">            0.614101</td></tr>\n",
       "<tr><td>train_and_evaluate_0fbd4677</td><td>TERMINATED</td><td>127.0.0.1:37851</td><td>(50, 10)</td><td>(10, 10)</td><td>(30, 30)</td><td>(10, 30)</td><td>(50, 40)</td><td>sigmoid     </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.284174</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.0027664  </td><td>(50, 20, 50)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.1138</td><td style=\"text-align: right;\">           0.162791</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.420816</td></tr>\n",
       "<tr><td>train_and_evaluate_8c31da8b</td><td>TERMINATED</td><td>127.0.0.1:37948</td><td>(20, 10)</td><td>(10, 50)</td><td>(40, 30)</td><td>(10, 10)</td><td>(50, 40)</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.317547</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000110139</td><td>(30, 30, 40)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         43.9521</td><td style=\"text-align: right;\">           0.142487</td><td style=\"text-align: right;\">           0.907407</td><td style=\"text-align: right;\">            0.578851</td></tr>\n",
       "<tr><td>train_and_evaluate_8f169f7d</td><td>TERMINATED</td><td>127.0.0.1:38024</td><td>(10, 50)</td><td>(10, 10)</td><td>(10, 40)</td><td>(40, 10)</td><td>(10, 40)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.437872</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000685418</td><td>(50, 20, 20)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         47.2916</td><td style=\"text-align: right;\">           0.15285 </td><td style=\"text-align: right;\">           0.691589</td><td style=\"text-align: right;\">            0.421981</td></tr>\n",
       "<tr><td>train_and_evaluate_b1d96305</td><td>TERMINATED</td><td>127.0.0.1:38103</td><td>(40, 30)</td><td>(30, 20)</td><td>(20, 10)</td><td>(50, 50)</td><td>(10, 40)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.34389 </td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000222868</td><td>(50, 50, 50)          </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        161.359 </td><td style=\"text-align: right;\">           0.168394</td><td style=\"text-align: right;\">           0.906542</td><td style=\"text-align: right;\">            0.576062</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=36532)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:05:53,351\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 20, 50), 'a2_output_hidden_layers': (50, 50), 'a3_output_hidden_layers': (10, 40), 'a4_output_hidden_layers': (10, 50), 'a12_output_hidden_layers': (20, 20), 'a21_output_hidden_layers': (10, 30)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=36825)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:08:09,164\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 10, 30), 'a2_output_hidden_layers': (10, 40), 'a3_output_hidden_layers': (20, 30), 'a4_output_hidden_layers': (50, 40), 'a12_output_hidden_layers': (50, 30), 'a21_output_hidden_layers': (50, 30)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=37091)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:09:33,096\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 40, 50), 'a2_output_hidden_layers': (40, 30), 'a3_output_hidden_layers': (50, 50), 'a4_output_hidden_layers': (40, 30), 'a12_output_hidden_layers': (20, 30), 'a21_output_hidden_layers': (30, 20)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=37229)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:10:19,620\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 10, 20), 'a2_output_hidden_layers': (30, 10), 'a3_output_hidden_layers': (10, 10), 'a4_output_hidden_layers': (20, 30), 'a12_output_hidden_layers': (30, 20), 'a21_output_hidden_layers': (30, 30)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=37323)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:12:36,307\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 10, 40), 'a2_output_hidden_layers': (30, 10), 'a3_output_hidden_layers': (30, 50), 'a4_output_hidden_layers': (50, 50), 'a12_output_hidden_layers': (20, 20), 'a21_output_hidden_layers': (30, 20)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=37664)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:13:45,605\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 30, 40), 'a2_output_hidden_layers': (30, 40), 'a3_output_hidden_layers': (10, 30), 'a4_output_hidden_layers': (50, 20), 'a12_output_hidden_layers': (40, 10), 'a21_output_hidden_layers': (30, 50)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=37851)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:14:31,870\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20, 50), 'a2_output_hidden_layers': (30, 30), 'a3_output_hidden_layers': (10, 30), 'a4_output_hidden_layers': (50, 40), 'a12_output_hidden_layers': (50, 10), 'a21_output_hidden_layers': (10, 10)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=37948)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:15:18,812\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 30, 40), 'a2_output_hidden_layers': (40, 30), 'a3_output_hidden_layers': (10, 10), 'a4_output_hidden_layers': (50, 40), 'a12_output_hidden_layers': (20, 10), 'a21_output_hidden_layers': (10, 50)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38024)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:16:09,136\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20, 20), 'a2_output_hidden_layers': (10, 40), 'a3_output_hidden_layers': (40, 10), 'a4_output_hidden_layers': (10, 40), 'a12_output_hidden_layers': (10, 50), 'a21_output_hidden_layers': (10, 10)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38103)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:18:53,257\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 50, 50), 'a2_output_hidden_layers': (20, 10), 'a3_output_hidden_layers': (50, 50), 'a4_output_hidden_layers': (10, 40), 'a12_output_hidden_layers': (40, 30), 'a21_output_hidden_layers': (30, 20)}\n",
      "2024-08-08 11:18:53,265\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-08-08_11-03-14' in 0.0062s.\n",
      "2024-08-08 11:18:53,270\tINFO tune.py:1041 -- Total run time: 938.69 seconds (938.64 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'activation': 'tanh', 'learning_rate': 0.0001558560745128232, 'batch_size': 32, 'shared_hidden_layers': (20, 20, 50), 'a2_output_hidden_layers': (50, 50), 'a3_output_hidden_layers': (10, 40), 'a4_output_hidden_layers': (10, 50), 'a12_output_hidden_layers': (20, 20), 'a21_output_hidden_layers': (10, 30), 'epochs': 50, 'dropout_rate': 0.3124471333566296}\n"
     ]
    }
   ],
   "source": [
    "analysis = five_fold_cross_validation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 11:27:55</td></tr>\n",
       "<tr><td>Running for: </td><td>00:09:02.50        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.2/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.5167315588382424<br>Logical resource usage: 10.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>a12_output_hidden_la\n",
       "yers             </th><th>a21_output_hidden_la\n",
       "yers             </th><th>a2_output_hidden_lay\n",
       "ers             </th><th>a3_output_hidden_lay\n",
       "ers             </th><th>a4_output_hidden_lay\n",
       "ers             </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  min_mean_accuracy</th><th style=\"text-align: right;\">  max_mean_accuracy</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_531f2178</td><td>TERMINATED</td><td>127.0.0.1:38349</td><td>(50, 10, 10)</td><td>(10, 40, 40)</td><td>(40, 10, 30)</td><td>(30, 30, 40)</td><td>(50, 40, 10)</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.338602</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.0041746  </td><td>(30, 50)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         18.3635</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.447304</td></tr>\n",
       "<tr><td>train_and_evaluate_95d7a382</td><td>TERMINATED</td><td>127.0.0.1:38384</td><td>(20, 40, 50)</td><td>(20, 10, 20)</td><td>(40, 30, 30)</td><td>(30, 30, 30)</td><td>(20, 50, 40)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.373649</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.0035967  </td><td>(40, 40)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         77.3525</td><td style=\"text-align: right;\">           0.178756</td><td style=\"text-align: right;\">           0.925926</td><td style=\"text-align: right;\">            0.627047</td></tr>\n",
       "<tr><td>train_and_evaluate_8a659726</td><td>TERMINATED</td><td>127.0.0.1:38506</td><td>(30, 30, 30)</td><td>(50, 20, 40)</td><td>(50, 20, 20)</td><td>(30, 10, 30)</td><td>(20, 20, 50)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.390993</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000519318</td><td>(50, 20)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         31.2397</td><td style=\"text-align: right;\">           0.155039</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.432234</td></tr>\n",
       "<tr><td>train_and_evaluate_8bfae06f</td><td>TERMINATED</td><td>127.0.0.1:38558</td><td>(30, 50, 30)</td><td>(20, 40, 10)</td><td>(10, 40, 10)</td><td>(20, 30, 30)</td><td>(50, 10, 50)</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.409637</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00747745 </td><td>(10, 10)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         32.4782</td><td style=\"text-align: right;\">           0.149871</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.43506 </td></tr>\n",
       "<tr><td>train_and_evaluate_d488345e</td><td>TERMINATED</td><td>127.0.0.1:38613</td><td>(20, 20, 50)</td><td>(10, 30, 50)</td><td>(20, 30, 20)</td><td>(50, 40, 50)</td><td>(20, 10, 40)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.281765</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000929103</td><td>(20, 40)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         77.8381</td><td style=\"text-align: right;\">           0.170984</td><td style=\"text-align: right;\">           0.906542</td><td style=\"text-align: right;\">            0.55587 </td></tr>\n",
       "<tr><td>train_and_evaluate_9c132b6a</td><td>TERMINATED</td><td>127.0.0.1:38734</td><td>(50, 50, 20)</td><td>(30, 10, 50)</td><td>(30, 20, 50)</td><td>(30, 30, 20)</td><td>(20, 30, 30)</td><td>tanh        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.34909 </td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00229859 </td><td>(20, 40)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         90.4829</td><td style=\"text-align: right;\">           0.176166</td><td style=\"text-align: right;\">           0.869565</td><td style=\"text-align: right;\">            0.543096</td></tr>\n",
       "<tr><td>train_and_evaluate_89211b3d</td><td>TERMINATED</td><td>127.0.0.1:38871</td><td>(50, 30, 20)</td><td>(20, 20, 40)</td><td>(10, 30, 40)</td><td>(10, 30, 30)</td><td>(30, 30, 40)</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.445953</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000279031</td><td>(30, 20)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.7367</td><td style=\"text-align: right;\">           0.150259</td><td style=\"text-align: right;\">           0.775701</td><td style=\"text-align: right;\">            0.490368</td></tr>\n",
       "<tr><td>train_and_evaluate_2370d817</td><td>TERMINATED</td><td>127.0.0.1:38909</td><td>(10, 50, 50)</td><td>(20, 50, 40)</td><td>(50, 30, 10)</td><td>(30, 10, 20)</td><td>(50, 40, 10)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.240243</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.0010253  </td><td>(40, 30)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         31.7522</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.766355</td><td style=\"text-align: right;\">            0.432953</td></tr>\n",
       "<tr><td>train_and_evaluate_f6c171af</td><td>TERMINATED</td><td>127.0.0.1:38962</td><td>(50, 50, 40)</td><td>(20, 30, 40)</td><td>(50, 50, 10)</td><td>(10, 20, 50)</td><td>(20, 10, 20)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.355865</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00023717 </td><td>(20, 50)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         77.5413</td><td style=\"text-align: right;\">           0.183938</td><td style=\"text-align: right;\">           0.897196</td><td style=\"text-align: right;\">            0.578225</td></tr>\n",
       "<tr><td>train_and_evaluate_28cb0e24</td><td>TERMINATED</td><td>127.0.0.1:39083</td><td>(30, 50, 30)</td><td>(40, 30, 30)</td><td>(30, 20, 20)</td><td>(20, 10, 40)</td><td>(10, 10, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.468288</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.000682819</td><td>(30, 20)              </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         61.4468</td><td style=\"text-align: right;\">           0.170984</td><td style=\"text-align: right;\">           0.898551</td><td style=\"text-align: right;\">            0.582107</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38349)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:19:14,358\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 50), 'a2_output_hidden_layers': (40, 10, 30), 'a3_output_hidden_layers': (30, 30, 40), 'a4_output_hidden_layers': (50, 40, 10), 'a12_output_hidden_layers': (50, 10, 10), 'a21_output_hidden_layers': (10, 40, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38384)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:20:34,148\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 40), 'a2_output_hidden_layers': (40, 30, 30), 'a3_output_hidden_layers': (30, 30, 30), 'a4_output_hidden_layers': (20, 50, 40), 'a12_output_hidden_layers': (20, 40, 50), 'a21_output_hidden_layers': (20, 10, 20)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38506)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:21:08,363\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20), 'a2_output_hidden_layers': (50, 20, 20), 'a3_output_hidden_layers': (30, 10, 30), 'a4_output_hidden_layers': (20, 20, 50), 'a12_output_hidden_layers': (30, 30, 30), 'a21_output_hidden_layers': (50, 20, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38558)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:21:43,391\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 10), 'a2_output_hidden_layers': (10, 40, 10), 'a3_output_hidden_layers': (20, 30, 30), 'a4_output_hidden_layers': (50, 10, 50), 'a12_output_hidden_layers': (30, 50, 30), 'a21_output_hidden_layers': (20, 40, 10)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38613)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:23:03,778\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 40), 'a2_output_hidden_layers': (20, 30, 20), 'a3_output_hidden_layers': (50, 40, 50), 'a4_output_hidden_layers': (20, 10, 40), 'a12_output_hidden_layers': (20, 20, 50), 'a21_output_hidden_layers': (10, 30, 50)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38734)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:24:36,542\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 40), 'a2_output_hidden_layers': (30, 20, 50), 'a3_output_hidden_layers': (30, 30, 20), 'a4_output_hidden_layers': (20, 30, 30), 'a12_output_hidden_layers': (50, 50, 20), 'a21_output_hidden_layers': (30, 10, 50)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38871)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:24:57,164\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 20), 'a2_output_hidden_layers': (10, 30, 40), 'a3_output_hidden_layers': (10, 30, 30), 'a4_output_hidden_layers': (30, 30, 40), 'a12_output_hidden_layers': (50, 30, 20), 'a21_output_hidden_layers': (20, 20, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38909)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:25:31,922\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 30), 'a2_output_hidden_layers': (50, 30, 10), 'a3_output_hidden_layers': (30, 10, 20), 'a4_output_hidden_layers': (50, 40, 10), 'a12_output_hidden_layers': (10, 50, 50), 'a21_output_hidden_layers': (20, 50, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=38962)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:26:52,143\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 50), 'a2_output_hidden_layers': (50, 50, 10), 'a3_output_hidden_layers': (10, 20, 50), 'a4_output_hidden_layers': (20, 10, 20), 'a12_output_hidden_layers': (50, 50, 40), 'a21_output_hidden_layers': (20, 30, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39083)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:27:55,817\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 20), 'a2_output_hidden_layers': (30, 20, 20), 'a3_output_hidden_layers': (20, 10, 40), 'a4_output_hidden_layers': (10, 10, 10), 'a12_output_hidden_layers': (30, 50, 30), 'a21_output_hidden_layers': (40, 30, 30)}\n",
      "2024-08-08 11:27:55,826\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-08-08_11-18-53' in 0.0069s.\n",
      "2024-08-08 11:27:55,831\tINFO tune.py:1041 -- Total run time: 542.54 seconds (542.50 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'activation': 'tanh', 'learning_rate': 0.0035966985028063796, 'batch_size': 64, 'shared_hidden_layers': (40, 40), 'a2_output_hidden_layers': (40, 30, 30), 'a3_output_hidden_layers': (30, 30, 30), 'a4_output_hidden_layers': (20, 50, 40), 'a12_output_hidden_layers': (20, 40, 50), 'a21_output_hidden_layers': (20, 10, 20), 'epochs': 50, 'dropout_rate': 0.37364854091239985}\n"
     ]
    }
   ],
   "source": [
    "analysis = five_fold_cross_validation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 11:37:46</td></tr>\n",
       "<tr><td>Running for: </td><td>00:09:50.82        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.3/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.47317765847607474<br>Logical resource usage: 10.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>a12_output_hidden_la\n",
       "yers                 </th><th>a21_output_hidden_la\n",
       "yers                 </th><th>a2_output_hidden_lay\n",
       "ers                 </th><th>a3_output_hidden_lay\n",
       "ers                 </th><th>a4_output_hidden_lay\n",
       "ers                 </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  min_mean_accuracy</th><th style=\"text-align: right;\">  max_mean_accuracy</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_55d772c1</td><td>TERMINATED</td><td>127.0.0.1:39178</td><td>(30, 40, 50, 20)</td><td>(20, 50, 40, 40)</td><td>(30, 10, 10, 30)</td><td>(50, 10, 10, 50)</td><td>(20, 20, 20, 40)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.487897</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000160233</td><td>(30,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         87.5962</td><td style=\"text-align: right;\">           0.160622</td><td style=\"text-align: right;\">           0.803738</td><td style=\"text-align: right;\">            0.480738</td></tr>\n",
       "<tr><td>train_and_evaluate_bdcc3831</td><td>TERMINATED</td><td>127.0.0.1:39316</td><td>(30, 40, 10, 30)</td><td>(40, 40, 40, 40)</td><td>(50, 10, 10, 20)</td><td>(40, 10, 20, 50)</td><td>(10, 40, 10, 40)</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.35132 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000138116</td><td>(40,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         17.6368</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.412248</td></tr>\n",
       "<tr><td>train_and_evaluate_3e16b40f</td><td>TERMINATED</td><td>127.0.0.1:39349</td><td>(40, 10, 50, 10)</td><td>(20, 40, 40, 30)</td><td>(50, 20, 40, 30)</td><td>(20, 10, 10, 50)</td><td>(50, 30, 40, 10)</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.340096</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000418922</td><td>(40,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         33.5506</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.42092 </td></tr>\n",
       "<tr><td>train_and_evaluate_90258679</td><td>TERMINATED</td><td>127.0.0.1:39407</td><td>(10, 20, 30, 40)</td><td>(20, 50, 40, 30)</td><td>(50, 40, 30, 40)</td><td>(30, 50, 10, 30)</td><td>(40, 50, 10, 50)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.322286</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000396665</td><td>(20,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         63.121 </td><td style=\"text-align: right;\">           0.160622</td><td style=\"text-align: right;\">           0.757009</td><td style=\"text-align: right;\">            0.465617</td></tr>\n",
       "<tr><td>train_and_evaluate_15ecffcb</td><td>TERMINATED</td><td>127.0.0.1:39503</td><td>(30, 10, 40, 50)</td><td>(40, 30, 20, 20)</td><td>(40, 50, 30, 30)</td><td>(50, 10, 50, 30)</td><td>(40, 20, 50, 20)</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.493719</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000409135</td><td>(30,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         41.2614</td><td style=\"text-align: right;\">           0.186528</td><td style=\"text-align: right;\">           0.915888</td><td style=\"text-align: right;\">            0.621265</td></tr>\n",
       "<tr><td>train_and_evaluate_d4ec1961</td><td>TERMINATED</td><td>127.0.0.1:39577</td><td>(30, 20, 50, 20)</td><td>(40, 20, 40, 20)</td><td>(50, 40, 30, 20)</td><td>(30, 30, 10, 40)</td><td>(30, 50, 30, 30)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.343611</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000113413</td><td>(30,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         31.7372</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.813084</td><td style=\"text-align: right;\">            0.503253</td></tr>\n",
       "<tr><td>train_and_evaluate_0e6e0de0</td><td>TERMINATED</td><td>127.0.0.1:39630</td><td>(30, 20, 50, 40)</td><td>(10, 50, 10, 10)</td><td>(10, 50, 20, 30)</td><td>(20, 20, 20, 30)</td><td>(30, 40, 50, 30)</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.285087</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00240919 </td><td>(20,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         59.5946</td><td style=\"text-align: right;\">           0.160622</td><td style=\"text-align: right;\">           0.869565</td><td style=\"text-align: right;\">            0.510954</td></tr>\n",
       "<tr><td>train_and_evaluate_ba1adfd7</td><td>TERMINATED</td><td>127.0.0.1:39724</td><td>(10, 40, 40, 30)</td><td>(30, 30, 30, 10)</td><td>(20, 50, 20, 10)</td><td>(40, 50, 30, 30)</td><td>(20, 50, 20, 20)</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.243468</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000213405</td><td>(30,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         91.7132</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.420134</td></tr>\n",
       "<tr><td>train_and_evaluate_82890b6e</td><td>TERMINATED</td><td>127.0.0.1:39873</td><td>(30, 10, 40, 10)</td><td>(50, 50, 30, 30)</td><td>(30, 20, 20, 40)</td><td>(50, 30, 30, 30)</td><td>(20, 30, 50, 10)</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.292889</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000141192</td><td>(30,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         45.4354</td><td style=\"text-align: right;\">           0.160622</td><td style=\"text-align: right;\">           0.87963 </td><td style=\"text-align: right;\">            0.55316 </td></tr>\n",
       "<tr><td>train_and_evaluate_284cf59f</td><td>TERMINATED</td><td>127.0.0.1:39942</td><td>(20, 10, 50, 30)</td><td>(40, 10, 30, 30)</td><td>(10, 50, 20, 10)</td><td>(40, 50, 20, 20)</td><td>(50, 40, 50, 20)</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.328009</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.00954775 </td><td>(30,)                 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         92.4519</td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.869159</td><td style=\"text-align: right;\">            0.461841</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39178)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:29:25,965\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (30, 10, 10, 30), 'a3_output_hidden_layers': (50, 10, 10, 50), 'a4_output_hidden_layers': (20, 20, 20, 40), 'a12_output_hidden_layers': (30, 40, 50, 20), 'a21_output_hidden_layers': (20, 50, 40, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39316)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:29:46,779\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40,), 'a2_output_hidden_layers': (50, 10, 10, 20), 'a3_output_hidden_layers': (40, 10, 20, 50), 'a4_output_hidden_layers': (10, 40, 10, 40), 'a12_output_hidden_layers': (30, 40, 10, 30), 'a21_output_hidden_layers': (40, 40, 40, 40)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39349)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:30:23,316\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40,), 'a2_output_hidden_layers': (50, 20, 40, 30), 'a3_output_hidden_layers': (20, 10, 10, 50), 'a4_output_hidden_layers': (50, 30, 40, 10), 'a12_output_hidden_layers': (40, 10, 50, 10), 'a21_output_hidden_layers': (20, 40, 40, 30)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39407)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:31:29,428\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20,), 'a2_output_hidden_layers': (50, 40, 30, 40), 'a3_output_hidden_layers': (30, 50, 10, 30), 'a4_output_hidden_layers': (40, 50, 10, 50), 'a12_output_hidden_layers': (10, 20, 30, 40), 'a21_output_hidden_layers': (20, 50, 40, 30)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39503)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:32:13,094\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (40, 50, 30, 30), 'a3_output_hidden_layers': (50, 10, 50, 30), 'a4_output_hidden_layers': (40, 20, 50, 20), 'a12_output_hidden_layers': (30, 10, 40, 50), 'a21_output_hidden_layers': (40, 30, 20, 20)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39577)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:32:47,685\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (50, 40, 30, 20), 'a3_output_hidden_layers': (30, 30, 10, 40), 'a4_output_hidden_layers': (30, 50, 30, 30), 'a12_output_hidden_layers': (30, 20, 50, 20), 'a21_output_hidden_layers': (40, 20, 40, 20)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39630)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:33:49,552\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20,), 'a2_output_hidden_layers': (10, 50, 20, 30), 'a3_output_hidden_layers': (20, 20, 20, 30), 'a4_output_hidden_layers': (30, 40, 50, 30), 'a12_output_hidden_layers': (30, 20, 50, 40), 'a21_output_hidden_layers': (10, 50, 10, 10)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39724)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:35:23,767\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (20, 50, 20, 10), 'a3_output_hidden_layers': (40, 50, 30, 30), 'a4_output_hidden_layers': (20, 50, 20, 20), 'a12_output_hidden_layers': (10, 40, 40, 30), 'a21_output_hidden_layers': (30, 30, 30, 10)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39873)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:36:11,809\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (30, 20, 20, 40), 'a3_output_hidden_layers': (50, 30, 30, 30), 'a4_output_hidden_layers': (20, 30, 50, 10), 'a12_output_hidden_layers': (30, 10, 40, 10), 'a21_output_hidden_layers': (50, 50, 30, 30)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=39942)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:37:46,684\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (10, 50, 20, 10), 'a3_output_hidden_layers': (40, 50, 20, 20), 'a4_output_hidden_layers': (50, 40, 50, 20), 'a12_output_hidden_layers': (20, 10, 50, 30), 'a21_output_hidden_layers': (40, 10, 30, 30)}\n",
      "2024-08-08 11:37:46,694\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-08-08_11-27-55' in 0.0083s.\n",
      "2024-08-08 11:37:46,698\tINFO tune.py:1041 -- Total run time: 590.86 seconds (590.81 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'activation': 'tanh', 'learning_rate': 0.0004091349628370055, 'batch_size': 128, 'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (40, 50, 30, 30), 'a3_output_hidden_layers': (50, 10, 50, 30), 'a4_output_hidden_layers': (40, 20, 50, 20), 'a12_output_hidden_layers': (30, 10, 40, 50), 'a21_output_hidden_layers': (40, 30, 20, 20), 'epochs': 50, 'dropout_rate': 0.49371946100111525}\n"
     ]
    }
   ],
   "source": [
    "analysis = five_fold_cross_validation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-08 11:46:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:09:12.22        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.1/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=7<br>Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: 0.4160280182216151<br>Logical resource usage: 10.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th>a12_output_hidden_la\n",
       "yers   </th><th>a21_output_hidden_la\n",
       "yers   </th><th>a2_output_hidden_lay\n",
       "ers   </th><th>a3_output_hidden_lay\n",
       "ers   </th><th>a4_output_hidden_lay\n",
       "ers   </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  learning_rate</th><th>shared_hidden_layers  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  min_mean_accuracy</th><th style=\"text-align: right;\">  max_mean_accuracy</th><th style=\"text-align: right;\">  mean_mean_accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_evaluate_2d674866</td><td>TERMINATED</td><td>127.0.0.1:40087</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.324692</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.000636043</td><td>(40, 40, 20, 40, 20)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        77.5284 </td><td style=\"text-align: right;\">           0.178756</td><td style=\"text-align: right;\">           0.869565</td><td style=\"text-align: right;\">            0.530234</td></tr>\n",
       "<tr><td>train_and_evaluate_86cf62a6</td><td>TERMINATED</td><td>127.0.0.1:40209</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.411232</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000643566</td><td>(20, 30, 10, 40, 10)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        26.9407 </td><td style=\"text-align: right;\">           0.165803</td><td style=\"text-align: right;\">           0.733333</td><td style=\"text-align: right;\">            0.425234</td></tr>\n",
       "<tr><td>train_and_evaluate_a939db8c</td><td>TERMINATED</td><td>127.0.0.1:40254</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.286991</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.00274373 </td><td>(50, 40, 40, 40, 10)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.059  </td><td style=\"text-align: right;\">           0.163212</td><td style=\"text-align: right;\">           0.647619</td><td style=\"text-align: right;\">            0.416223</td></tr>\n",
       "<tr><td>train_and_evaluate_31b50451</td><td>TERMINATED</td><td>127.0.0.1:40276</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>tanh        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.438282</td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000210609</td><td>(10, 10, 10, 30, 40)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        47.5701 </td><td style=\"text-align: right;\">           0.150259</td><td style=\"text-align: right;\">           0.794393</td><td style=\"text-align: right;\">            0.469081</td></tr>\n",
       "<tr><td>train_and_evaluate_3e512bdf</td><td>TERMINATED</td><td>127.0.0.1:40353</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>sigmoid     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.3568  </td><td style=\"text-align: right;\">      30</td><td style=\"text-align: right;\">    0.000215582</td><td>(50, 40, 50, 10, 20)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        49.3756 </td><td style=\"text-align: right;\">           0.144703</td><td style=\"text-align: right;\">           0.704762</td><td style=\"text-align: right;\">            0.410393</td></tr>\n",
       "<tr><td>train_and_evaluate_ae3e09d4</td><td>TERMINATED</td><td>127.0.0.1:40432</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>sigmoid     </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.316868</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">    0.00408404 </td><td>(30, 20, 50, 40, 40)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       168.971  </td><td style=\"text-align: right;\">           0.15544 </td><td style=\"text-align: right;\">           0.695238</td><td style=\"text-align: right;\">            0.415833</td></tr>\n",
       "<tr><td>train_and_evaluate_035cdbe4</td><td>TERMINATED</td><td>127.0.0.1:40691</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.368083</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">    0.00462388 </td><td>(50, 20, 50, 20, 50)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        64.3716 </td><td style=\"text-align: right;\">           0.158031</td><td style=\"text-align: right;\">           0.785047</td><td style=\"text-align: right;\">            0.488404</td></tr>\n",
       "<tr><td>train_and_evaluate_02dc33a8</td><td>TERMINATED</td><td>127.0.0.1:40794</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      0.485479</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.000408309</td><td>(50, 50, 10, 50, 30)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        35.0496 </td><td style=\"text-align: right;\">           0.152455</td><td style=\"text-align: right;\">           0.580952</td><td style=\"text-align: right;\">            0.40914 </td></tr>\n",
       "<tr><td>train_and_evaluate_e9afec9e</td><td>TERMINATED</td><td>127.0.0.1:40860</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>relu        </td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      0.391072</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">    0.001514   </td><td>(20, 40, 20, 20, 50)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.87237</td><td style=\"text-align: right;\">           0.149871</td><td style=\"text-align: right;\">           0.657143</td><td style=\"text-align: right;\">            0.413396</td></tr>\n",
       "<tr><td>train_and_evaluate_d033b27d</td><td>TERMINATED</td><td>127.0.0.1:40881</td><td>()</td><td>()</td><td>()</td><td>()</td><td>()</td><td>sigmoid     </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      0.488088</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">    0.000968123</td><td>(10, 40, 20, 30, 10)  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        33.8304 </td><td style=\"text-align: right;\">           0.15285 </td><td style=\"text-align: right;\">           0.657143</td><td style=\"text-align: right;\">            0.406607</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40087)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:39:06,767\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (40, 40, 20, 40, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40209)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:39:36,529\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 30, 10, 40, 10), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40254)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:39:49,688\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 40, 40, 40, 10), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40276)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:40:40,283\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 10, 10, 30, 40), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40353)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:41:32,035\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 40, 50, 10, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40432)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:44:24,172\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (30, 20, 50, 40, 40), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40691)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:45:31,604\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 20, 50, 20, 50), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40794)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:46:09,044\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (50, 50, 10, 50, 30), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40860)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:46:21,951\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (20, 40, 20, 20, 50), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_and_evaluate pid=40881)\u001b[0m <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 11:46:58,970\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'shared_hidden_layers': (10, 40, 20, 30, 10), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': ()}\n",
      "2024-08-08 11:46:58,981\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/bhanuprasanna/Documents/Uniklinik-Koln/MTL/spike-sorting-multi-task/ray_results/train_and_evaluate_2024-08-08_11-37-46' in 0.0086s.\n",
      "2024-08-08 11:46:58,989\tINFO tune.py:1041 -- Total run time: 552.28 seconds (552.21 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found were:  {'activation': 'relu', 'learning_rate': 0.0006360430333978182, 'batch_size': 64, 'shared_hidden_layers': (40, 40, 20, 40, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': (), 'epochs': 50, 'dropout_rate': 0.3246924305272304}\n"
     ]
    }
   ],
   "source": [
    "analysis = five_fold_cross_validation(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_A2 = pd.read_pickle(\"results/Feature_based_output_A2.pkl\")\n",
    "df_dict_A3 = pd.read_pickle(\"results/Feature_based_output_A3.pkl\")\n",
    "df_dict_A4 = pd.read_pickle(\"results/Feature_based_output_A4.pkl\")\n",
    "df_dict_A12 = pd.read_pickle(\"results/Feature_based_output_A12.pkl\")\n",
    "df_dict_A21 = pd.read_pickle(\"results/Feature_based_output_A21.pkl\")\n",
    "\n",
    "df_dict = pd.concat([df_dict_A2, df_dict_A3, df_dict_A4, df_dict_A12, df_dict_A21])\n",
    "\n",
    "df_dict = df_dict.loc[:,~df_dict.columns.duplicated()].copy()\n",
    "df_dict = df_dict.drop_duplicates()\n",
    "\n",
    "df_dict.to_csv('outputs/Feature_based_one_split_metrics_system.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_full_A2 = pd.read_pickle(\"results/Feature_based_output_full_A2.pkl\")\n",
    "df_dict_full_A3 = pd.read_pickle(\"results/Feature_based_output_full_A3.pkl\")\n",
    "df_dict_full_A4 = pd.read_pickle(\"results/Feature_based_output_full_A4.pkl\")\n",
    "df_dict_full_A12 = pd.read_pickle(\"results/Feature_based_output_full_A12.pkl\")\n",
    "df_dict_full_A21 = pd.read_pickle(\"results/Feature_based_output_full_A21.pkl\")\n",
    "\n",
    "df_full_dict = pd.concat([df_dict_full_A2, df_dict_full_A3, df_dict_full_A4, df_dict_full_A12, df_dict_full_A21])\n",
    "\n",
    "df_full_dict = df_full_dict.loc[:, ~df_full_dict.columns.duplicated()].copy()\n",
    "df_full_dict = df_full_dict.drop_duplicates()\n",
    "\n",
    "df_full_dict.to_csv(\"outputs/Feature_based__full_split_metrics_system.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_full_A2.to_csv(\"outputs/Feature_based_full_split_metrics_A2.csv\")\n",
    "df_dict_full_A3.to_csv(\"outputs/Feature_based_full_split_metrics_A3.csv\")\n",
    "df_dict_full_A4.to_csv(\"outputs/Feature_based_full_split_metrics_A4.csv\")\n",
    "df_dict_full_A12.to_csv(\"outputs/Feature_based_full_split_metrics_A12.csv\")\n",
    "df_dict_full_A21.to_csv(\"outputs/Feature_based_full_split_metrics_A21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for config {'activation': 'tanh', 'learning_rate': 0.0009012544512547965, 'batch_size': 32, 'shared_hidden_layers': (10, 10, 50, 30, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': (), 'epochs': 50, 'dropout_rate': 0.4271563988934437} is 0.6107975608816163\n",
      "Mean accuracy for config {'activation': 'tanh', 'learning_rate': 0.001137191002648876, 'batch_size': 128, 'shared_hidden_layers': (50, 40, 20, 20), 'a2_output_hidden_layers': (40,), 'a3_output_hidden_layers': (30,), 'a4_output_hidden_layers': (20,), 'a12_output_hidden_layers': (20,), 'a21_output_hidden_layers': (20,), 'epochs': 50, 'dropout_rate': 0.3383933955559252} is 0.6122718885721694\n",
      "Mean accuracy for config {'activation': 'tanh', 'learning_rate': 0.0001558560745128232, 'batch_size': 32, 'shared_hidden_layers': (20, 20, 50), 'a2_output_hidden_layers': (50, 50), 'a3_output_hidden_layers': (10, 40), 'a4_output_hidden_layers': (10, 50), 'a12_output_hidden_layers': (20, 20), 'a21_output_hidden_layers': (10, 30), 'epochs': 50, 'dropout_rate': 0.3124471333566296} is 0.6274835534846714\n",
      "Mean accuracy for config {'activation': 'tanh', 'learning_rate': 0.0035966985028063796, 'batch_size': 64, 'shared_hidden_layers': (40, 40), 'a2_output_hidden_layers': (40, 30, 30), 'a3_output_hidden_layers': (30, 30, 30), 'a4_output_hidden_layers': (20, 50, 40), 'a12_output_hidden_layers': (20, 40, 50), 'a21_output_hidden_layers': (20, 10, 20), 'epochs': 50, 'dropout_rate': 0.37364854091239985} is 0.6270470884271093\n",
      "Mean accuracy for config {'activation': 'tanh', 'learning_rate': 0.0004091349628370055, 'batch_size': 128, 'shared_hidden_layers': (30,), 'a2_output_hidden_layers': (40, 50, 30, 30), 'a3_output_hidden_layers': (50, 10, 50, 30), 'a4_output_hidden_layers': (40, 20, 50, 20), 'a12_output_hidden_layers': (30, 10, 40, 50), 'a21_output_hidden_layers': (40, 30, 20, 20), 'epochs': 50, 'dropout_rate': 0.49371946100111525} is 0.621264759030724\n",
      "Mean accuracy for config {'activation': 'relu', 'learning_rate': 0.0006360430333978182, 'batch_size': 64, 'shared_hidden_layers': (40, 40, 20, 40, 20), 'a2_output_hidden_layers': (), 'a3_output_hidden_layers': (), 'a4_output_hidden_layers': (), 'a12_output_hidden_layers': (), 'a21_output_hidden_layers': (), 'epochs': 50, 'dropout_rate': 0.3246924305272304} is 0.5302336935058369\n",
      "The best config is {'activation': 'tanh', 'learning_rate': 0.0001558560745128232, 'batch_size': 32, 'shared_hidden_layers': (20, 20, 50), 'a2_output_hidden_layers': (50, 50), 'a3_output_hidden_layers': (10, 40), 'a4_output_hidden_layers': (10, 50), 'a12_output_hidden_layers': (20, 20), 'a21_output_hidden_layers': (10, 30), 'epochs': 50, 'dropout_rate': 0.3124471333566296} with a mean accuracy of 0.6274835534846714\n",
      "             name  mean_accuracy  std_accuracy  mean_f1_macro  std_f1_macro  \\\n",
      "20    a2_15cea493       0.889910      0.020886       0.889513      0.020884   \n",
      "80    a3_15cea493       0.887205      0.034972       0.886942      0.035051   \n",
      "140   a4_15cea493       0.459324      0.022966       0.385052      0.038986   \n",
      "200  a12_15cea493       0.212731      0.023579       0.122467      0.019591   \n",
      "260  a21_15cea493       0.688248      0.050293       0.627680      0.033491   \n",
      "\n",
      "     mean_f1_micro  std_f1_micro  mean_mcc   std_mcc  \n",
      "20        0.889910      0.020886  0.785964  0.042151  \n",
      "80        0.887205      0.034972  0.777513  0.069207  \n",
      "140       0.459324      0.022966  0.230155  0.031830  \n",
      "200       0.212731      0.023579  0.069263  0.032966  \n",
      "260       0.688248      0.050293  0.345450  0.054494  \n"
     ]
    }
   ],
   "source": [
    "# print the configs and results for the hyperparemters wiht the highest mean accuracy\n",
    "# read df_full_dict and print columns with configs in best_params_list_getting\n",
    "df_full_dict = pd.read_csv(\"outputs/Feature_based__full_split_metrics_system.csv\")\n",
    "\n",
    "config_acc_dict = {}\n",
    "for good_param in best_params_list_getting:\n",
    "    # get the row witht the highest mean mean accuracy\n",
    "    mean_accuracy = df_full_dict.loc[df_full_dict['config'] == str(good_param)]['mean_accuracy'].mean()\n",
    "    config_acc_dict[str(good_param)] = mean_accuracy\n",
    "    print(f\"Mean accuracy for config {good_param} is {mean_accuracy}\")\n",
    "\n",
    "# get the best config\n",
    "best_config = max(config_acc_dict, key=config_acc_dict.get)\n",
    "print(f\"The best config is {best_config} with a mean accuracy of {config_acc_dict[best_config]}\")\n",
    "\n",
    "#print aggregate results for the best config\n",
    "metrics = ['name', 'mean_accuracy', 'std_accuracy', 'mean_f1_macro', 'std_f1_macro', 'mean_f1_micro', 'std_f1_micro', 'mean_mcc', 'std_mcc']\n",
    "print(df_full_dict[metrics].loc[df_full_dict['config'] == best_config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
